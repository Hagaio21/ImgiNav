# Stage 2: Discriminator Training (NEW)
# This replaces the old Stage 2 which wasn't working well.
# 
# Pipeline:
# 1. Load Stage 1 checkpoint
# 2. Generate N fake samples from model
# 3. Get N real samples from dataset and encode to latents
# 4. Train discriminator on these latents
# 5. Train diffusion model with discriminator loss
# 6. Optionally iterate this process (adversarial training)

experiment:
  name: "diffusion_stage2_discriminator_base"  # Will be customized per experiment
  phase: "diffusion_stage2_discriminator"
  save_path: "/work3/s233249/ImgiNav/experiments/diffusion/stage2_discriminator"

# Stage 1 checkpoint to load (required)
# Update this path to point to your Stage 1 best checkpoint
diffusion:
  stage1_checkpoint: /work3/s233249/ImgiNav/experiments/diffusion/ablation/capacity_unet128_d4/diffusion_ablation_capacity_unet128_d4_checkpoint_best.pt

# Autoencoder config (decoder stays frozen - only UNet is trained)
autoencoder:
  checkpoint: /work3/s233249/ImgiNav/experiments/phase1/phase1_6_AE_normalized/phase1_6_AE_normalized_checkpoint_best.pt
  frozen: true  # Keep decoder frozen - discriminator loss guides UNet only

# Discriminator config (optional - will use defaults if not specified)
discriminator:
  config:
    latent_channels: 16
    base_channels: 64
    num_layers: 4
    use_batch_norm: true

# Dataset: Need latent path for training
dataset:
  manifest: "/work3/s233249/ImgiNav/datasets/augmented/manifest.csv"
  outputs:
    latent: "latent_path"  # Pre-embedded latents
  filters:
    is_empty: [false]
  return_path: false

# UNet config (inherited from Stage 1 checkpoint, but can override)
unet:
  in_channels: 16
  out_channels: 16
  base_channels: 128
  depth: 4
  num_res_blocks: 2
  time_dim: 128
  cond_channels: 0
  fusion_mode: "none"
  norm_groups: 8
  dropout: 0.2

# Scheduler (inherited from Stage 1 checkpoint)
scheduler:
  type: "CosineScheduler"
  num_steps: 500

training:
  seed: 42
  train_split: 0.8
  split_seed: 42
  batch_size: 32  # Smaller batch size for discriminator training
  num_workers: 8
  shuffle: true
  epochs: 50  # Per iteration (will be overridden by --diffusion_epochs)
  learning_rate: 0.00005  # Lower learning rate for fine-tuning
  optimizer: AdamW
  weight_decay: 0.1
  
  # Checkpoint settings
  save_interval: 99999  # Disable periodic checkpoints
  eval_interval: 5  # Evaluate every 5 epochs
  sample_interval: 10  # Generate samples every 10 epochs
  
  # Mixed precision for efficiency
  use_amp: true
  
  # Gradient clipping for stability
  max_grad_norm: 0.5
  
  # Weighted sampling disabled
  use_weighted_sampling: false
  
  # Loss configuration
  # Must include DiscriminatorLoss for adversarial training
  loss:
    type: CompositeLoss
    losses:
      # Noise prediction loss (primary)
      - type: MSELoss
        key: "pred_noise"
        target: "noise"
        weight: 1.0
      
      # Discriminator adversarial loss
      # The discriminator will be loaded dynamically during training
      - type: DiscriminatorLoss
        key: "pred_latent"  # Key in preds dict for predicted latents
        weight: 0.3  # Increased from 0.1 for stronger adversarial signal
        target: null  # Discriminator loss doesn't need targets

