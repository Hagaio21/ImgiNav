# New Layouts: Variational Autoencoder (VAE) with Strong KL Regularization (256×256)
# Optimized for new layout dataset: 256×256 input → 64×64×4 latents
# Architecture: 64×64×4 = 16,384 dims
# Encoder: VAE with strong KL divergence regularization
# Loss: MSE=1.0, KLD=0.1 (strong KL divergence for N(0,1) latent space)

experiment:
  name: "new_layouts_VAE_64x64_structural_256"
  phase: "new_layouts_structural_training"
  save_path: "/work3/s233249/ImgiNav/experiments/new_layouts/new_layouts_VAE_64x64_structural_256"

dataset:
  manifest: "/work3/s233249/ImgiNav/datasets/layouts_cleaned.csv"
  outputs:
    rgb: "layout_path"
    label: "type"
  filters:
    is_empty: [false]
  return_path: false
  # Add resize transform for 256×256 input
  transform:
    type: Compose
    transforms:
      - type: Resize
        size: [256, 256]
        interpolation: nearest  # Preserve exact RGB values for class matching
      - type: ToTensor
      - type: Normalize
        mean: [0.5, 0.5, 0.5]
        std: [0.5, 0.5, 0.5]  # Normalizes to [-1, 1] range

autoencoder:
  encoder:
    in_channels: 3
    latent_channels: 4  # 64×64×4 latent space
    base_channels: 48  # Capacity 48 (smallest model)
    downsampling_steps: 2  # 256 -> 128 -> 64 (64×64 spatial resolution)
    activation: SiLU
    norm_groups: 8
    variational: true  # VAE mode: outputs mu and logvar
  
  decoder:
    latent_channels: 4  # 64×64×4 latent space
    base_channels: 48  # Capacity 48 (smallest model)
    upsampling_steps: 2  # 64 -> 128 -> 256 (64×64 spatial resolution)
    activation: SiLU
    norm_groups: 8
    heads:
      - type: RGBHead
        name: rgb
        out_channels: 3
        final_activation: tanh

training:
  seed: 42
  train_split: 0.8
  split_seed: 42
  batch_size: 32
  num_workers: 8
  shuffle: true
  epochs: 150
  learning_rate: 0.0001
  optimizer: AdamW
  weight_decay: 0.02
  save_interval: 5
  sample_interval: 1
  early_stopping_patience: 5
  early_stopping_min_delta: 0.0001
  early_stopping_restore_best: true
  
  loss:
    type: CompositeLoss
    losses:
      - type: MSELoss
        key: rgb
        target: rgb
        weight: 1.0
      - type: KLDLoss
        weight: 0.0001  # Strong KL divergence loss (encourages N(0,1) latent space)
      - type: LatentStandardizationLoss
        key: mu
        weight: 0.1
        mean_penalty_type: l2
        std_penalty_type: l2
        per_channel: true

