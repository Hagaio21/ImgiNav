experiment:
  name: controlnet_ablation_capacity_unet32_d3
  phase: controlnet_ablation
  save_path: experiments/controlnet/ablation/capacity_unet32_d3

# PLACEHOLDER: Update with actual checkpoint path after diffusion training completes
diffusion:
  checkpoint: PLACEHOLDER_PATH_TO_DIFFUSION_CHECKPOINT  # Update: /work3/s233249/ImgiNav/experiments/diffusion/ablation/capacity_unet32_d3/diffusion_ablation_capacity_unet32_d3_checkpoint_best.pt

autoencoder:
  checkpoint: /work3/s233249/ImgiNav/experiments/phase1/phase1_6_AE_normalized/phase1_6_AE_normalized_checkpoint_best.pt
  frozen: true

dataset:
  manifest: /work3/s233249/ImgiNav/datasets/controlnet_training_manifest.csv
  outputs:
    latent: layout_embedding_path
    text_emb: graph_embedding_path
    pov_emb: pov_embedding_path
  filters:
    is_empty: [false]
  return_path: false

controlnet:
  adapter:
    type: SimpleAdapter
    text_dim: 384
    pov_dim: 512
    base_channels: 32  # Matches UNet base_channels
    depth: 3            # Matches UNet depth
    pov_is_spatial: false
  fusion:
    type: scaled_add
    init_scale: 0.0  # Zero Convolution initialization: start at 0.0 so control features have no initial effect

debug_control_features: true  # Enable debug logging for control feature magnitudes during training

training:
  seed: 123
  train_split: 0.8
  split_seed: 123
  batch_size: 32
  num_workers: 4
  shuffle: true
  epochs: 100
  learning_rate: 0.00001  # Lowered from 1e-4 to 1e-5 to prevent gradient explosion with Zero Convolution
  optimizer: AdamW
  weight_decay: 0.01
  save_interval: 10
  eval_interval: 5
  sample_interval: 10
  use_amp: true
  max_grad_norm: 0.5  # Tightened from 1.0 to 0.5 for more aggressive gradient clipping
  loss:
    type: MSELoss
    key: pred_noise
    target: noise
    weight: 1.0

