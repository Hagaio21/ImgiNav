"""
Diffusion-specific loss components.
These losses require model components (scheduler, discriminator, decoder) as context.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from .base_loss import LossComponent, register_loss


@register_loss
class SNRWeightedNoiseLoss(LossComponent):
    """
    SNR-weighted noise prediction loss for diffusion training.
    
    Computes: loss = mean((pred_noise - noise)^2 * w) where w = snr / (1 + snr)
    and snr = alpha_bar / (1 - alpha_bar)
    
    Config:
        key: Key in preds for predicted noise (default: "pred_noise")
        target: Key in targets for target noise (default: "noise")
        weight: Loss weight (default: 1.0)
    
    Requires scheduler and timesteps to be passed in preds:
        preds["scheduler"]: Diffusion scheduler (for alpha_bars)
        preds["timesteps"]: Timestep tensor [B]
    """
    
    def _build(self):
        super()._build()
        # Set defaults if not specified
        if self.key is None:
            self.key = "pred_noise"
        if self.target_key is None:
            self.target_key = "noise"
    
    def forward(self, preds, targets):
        if self.key not in preds or self.target_key not in targets:
            device = preds.get(self.key, targets.get(self.target_key, torch.zeros(1)))
            if isinstance(device, torch.Tensor):
                device = device.device
            else:
                device = torch.device("cpu")
            return torch.tensor(0.0, device=device), {}
        
        pred_noise = preds[self.key]
        noise_target = targets[self.target_key]
        scheduler = preds.get("scheduler")
        timesteps = preds.get("timesteps")
        
        if scheduler is None or timesteps is None:
            # Fallback to unweighted MSE if scheduler/timesteps not provided
            loss = ((pred_noise - noise_target).pow(2)).mean() * self.weight
            return loss, {f"noise_loss": loss.detach()}
        
        # Compute SNR-weighted loss
        device_obj = pred_noise.device
        alpha_bars = scheduler.alpha_bars.to(device_obj)
        alpha_bar = alpha_bars[timesteps].view(-1, 1, 1, 1)  # [B, 1, 1, 1]
        snr = alpha_bar / (1 - alpha_bar + 1e-8)  # Signal-to-noise ratio
        w = snr / (1 + snr)  # SNR weighting
        
        loss = ((pred_noise - noise_target).pow(2) * w).mean() * self.weight
        return loss, {f"noise_loss": loss.detach()}


@register_loss
class DiscriminatorLoss(LossComponent):
    """
    Discriminator adversarial loss for diffusion training.
    
    The discriminator was trained to distinguish between TRUE layouts (real, from dataset) 
    and FAKE layouts (generated by the diffusion model). This loss evaluates the discriminator
    on PREDICTED/GENERATED latents (fake layouts) and encourages the model to generate
    latents that the discriminator classifies as viable (score → 1.0).
    
    Loss direction: HIGH when discriminator scores LOW (fake), LOW when discriminator scores HIGH (real)
    This encourages the model to generate latents that fool the discriminator (score → 1.0).
    
    Computes: loss = -log(viability_score.mean() + eps) * weight
    where viability_score comes from discriminator(pred_latent)
    
    Config:
        key: Key in preds for predicted latent (default: "pred_latent")
        weight: Loss weight (default: 1.0)
        target: Not used (discriminator doesn't need targets)
    
    Requires:
        preds["discriminator"]: LatentDiscriminator model
        preds["pred_latent"]: Predicted/denoised latents [B, C, H, W] (fake layouts)
    """
    
    def _build(self):
        super()._build()
        # Set defaults if not specified - use "pred_latent" (denoised from real) to align with training objective
        if self.key is None:
            self.key = "pred_latent"  # Use the same latents as the denoising loss for consistency
        # Debug: Log the key being used
        print(f"DiscriminatorLoss initialized with key='{self.key}', weight={self.weight}")
        # Discriminator loss doesn't use targets
    
    def forward(self, preds, targets):
        discriminator = preds.get("discriminator")
        if discriminator is None:
            # Debug: log why discriminator is missing
            if not hasattr(self, '_warned_no_discriminator'):
                print(f"WARNING: DiscriminatorLoss - discriminator not found in preds. Available keys: {list(preds.keys())}")
                self._warned_no_discriminator = True
            device = preds.get("pred_latent", torch.zeros(1))
            if isinstance(device, torch.Tensor):
                device = device.device
            else:
                device = torch.device("cpu")
            return torch.tensor(0.0, device=device), {}
        
        # Get predicted latents (denoised from real latents during training)
        # Using pred_latent aligns the discriminator loss with the actual denoising objective
        generated_latents = preds.get(self.key)
        if generated_latents is None:
            # Debug: log why latents are missing
            if not hasattr(self, '_warned_no_latent'):
                print(f"WARNING: DiscriminatorLoss - {self.key} not found in preds. Available keys: {list(preds.keys())}")
                self._warned_no_latent = True
            device = preds.get("pred_noise", torch.zeros(1))
            if isinstance(device, torch.Tensor):
                device = device.device
            else:
                device = torch.device("cpu")
            return torch.tensor(0.0, device=device), {}
        
        # Get viability scores from discriminator on PREDICTED/GENERATED latents (fake layouts)
        # The discriminator was trained to distinguish: real (score=1.0) vs fake (score=0.0)
        # We want the generated latents to be classified as viable (score → 1.0)
        
        # Ensure discriminator is in eval mode (should already be, but double-check)
        if discriminator.training:
            discriminator.eval()
        
        # Note: We need gradients for viability_scores to compute loss gradients
        # The discriminator is frozen (requires_grad=False), so no gradients flow through it
        # but the output still needs to be part of the computation graph for loss backprop
        viability_scores = discriminator(generated_latents)  # [B, 1] in [0, 1]
        
        # Debug: Log discriminator scores with timestep info
        timesteps = preds.get("timesteps")
        if timesteps is not None and not hasattr(self, '_logged_discriminator_stats'):
            score_mean = viability_scores.mean().item()
            score_min = viability_scores.min().item()
            score_max = viability_scores.max().item()
            score_std = viability_scores.std().item()
            t_mean = timesteps.float().mean().item()
            t_min = timesteps.min().item()
            t_max = timesteps.max().item()
            print(f"DiscriminatorLoss DEBUG - Scores: mean={score_mean:.6f}, min={score_min:.6f}, max={score_max:.6f}, std={score_std:.6f}")
            print(f"DiscriminatorLoss DEBUG - Timesteps: mean={t_mean:.1f}, range=[{t_min}, {t_max}]")
            print(f"DiscriminatorLoss DEBUG - pred_latents shape: {generated_latents.shape}, range: [{generated_latents.min().item():.3f}, {generated_latents.max().item():.3f}]")
            self._logged_discriminator_stats = True
        elif not hasattr(self, '_logged_discriminator_stats'):
            score_mean = viability_scores.mean().item()
            score_min = viability_scores.min().item()
            score_max = viability_scores.max().item()
            score_std = viability_scores.std().item()
            print(f"DiscriminatorLoss DEBUG - Scores: mean={score_mean:.6f}, min={score_min:.6f}, max={score_max:.6f}, std={score_std:.6f}")
            print(f"DiscriminatorLoss DEBUG - pred_latents shape: {generated_latents.shape}, range: [{generated_latents.min().item():.3f}, {generated_latents.max().item():.3f}]")
            print(f"DiscriminatorLoss DEBUG - WARNING: No timesteps in preds!")
            self._logged_discriminator_stats = True
        
        # Adversarial loss: inverse of discriminator score
        # High when fake (score→0), low when real (score→1)
        # This encourages model to generate latents that fool discriminator
        loss = -torch.log(viability_scores.mean() + 1e-8) * self.weight
        
        return loss, {
            "discriminator_loss": loss.detach(),
            "viability_score": viability_scores.mean().detach()
        }


@register_loss
class LatentStructuralLoss(LossComponent):
    """
    Latent-space structural loss for diffusion training.
    
    Computes Sobel or Laplacian gradients on both predicted and ground-truth latents,
    then minimizes their difference. This encourages the UNet to learn spatially coherent
    latent representations where boundaries and transitions align with real layout geometry.
    
    The loss is SNR-weighted: it applies more weight at low noise levels (high alpha_bar)
    where the predicted x0 is more accurate, and less weight at high noise levels where
    the predicted x0 is expected to be noisy even with perfect noise prediction.
    
    Config:
        key: Key in preds for predicted noise (default: "pred_noise")
        target: Key in targets for ground-truth latent (default: "latent")
        weight: Loss weight (default: 1.0)
        gradient_type: "sobel" or "laplacian" (default: "sobel")
        reduction: "mean" or "sum" for gradient magnitude reduction (default: "mean")
    
    Requires scheduler, timesteps, and noisy_latent to be passed in preds:
        preds["scheduler"]: Diffusion scheduler (for alpha_bars)
        preds["timesteps"]: Timestep tensor [B]
        preds["noisy_latent"]: Noisy latents [B, C, H, W]
    """
    
    def _build(self):
        super()._build()
        # Set defaults if not specified
        if self.key is None:
            self.key = "pred_noise"
        if self.target_key is None:
            self.target_key = "latent"
        
        # Gradient computation type
        self.gradient_type = self._init_kwargs.get("gradient_type", "sobel").lower()
        if self.gradient_type not in ["sobel", "laplacian"]:
            raise ValueError(f"gradient_type must be 'sobel' or 'laplacian', got '{self.gradient_type}'")
        
        # Reduction method for gradient magnitude
        self.reduction = self._init_kwargs.get("reduction", "mean")
        
        # Build Sobel kernels if needed
        if self.gradient_type == "sobel":
            # Sobel kernels for x and y gradients
            sobel_x = torch.tensor([[-1, 0, 1],
                                    [-2, 0, 2],
                                    [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3)
            sobel_y = torch.tensor([[-1, -2, -1],
                                    [0, 0, 0],
                                    [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3)
            self.register_buffer("sobel_x", sobel_x)
            self.register_buffer("sobel_y", sobel_y)
        
        # Laplacian kernel
        elif self.gradient_type == "laplacian":
            laplacian = torch.tensor([[0, -1, 0],
                                     [-1, 4, -1],
                                     [0, -1, 0]], dtype=torch.float32).view(1, 1, 3, 3)
            self.register_buffer("laplacian", laplacian)
    
    def _compute_gradients(self, latents):
        """
        Compute gradients on latents using Sobel or Laplacian operator.
        
        Args:
            latents: Tensor [B, C, H, W]
        
        Returns:
            Gradient magnitude tensor [B, C, H, W] (for Sobel) or [B, C, H, W] (for Laplacian)
        """
        B, C, H, W = latents.shape
        device = latents.device
        
        if self.gradient_type == "sobel":
            # Apply Sobel filters to each channel
            # Expand kernels to match number of channels and ensure they're on the same device
            sobel_x = self.sobel_x.to(device).expand(C, 1, 3, 3)
            sobel_y = self.sobel_y.to(device).expand(C, 1, 3, 3)
            
            # Compute gradients for each channel
            grad_x = F.conv2d(latents, sobel_x, padding=1, groups=C)
            grad_y = F.conv2d(latents, sobel_y, padding=1, groups=C)
            
            # Compute gradient magnitude
            gradients = torch.sqrt(grad_x.pow(2) + grad_y.pow(2) + 1e-8)
        
        else:  # laplacian
            # Apply Laplacian filter to each channel
            laplacian_kernel = self.laplacian.to(device).expand(C, 1, 3, 3)
            gradients = F.conv2d(latents, laplacian_kernel, padding=1, groups=C)
            # Take absolute value for Laplacian (second derivative can be negative)
            gradients = torch.abs(gradients)
        
        return gradients
    
    def forward(self, preds, targets):
        # Check required keys
        if self.key not in preds or self.target_key not in targets:
            device = preds.get(self.key, targets.get(self.target_key, torch.zeros(1)))
            if isinstance(device, torch.Tensor):
                device = device.device
            else:
                device = torch.device("cpu")
            return torch.tensor(0.0, device=device), {}
        
        pred_noise = preds[self.key]
        gt_latents = targets[self.target_key]
        scheduler = preds.get("scheduler")
        timesteps = preds.get("timesteps")
        noisy_latents = preds.get("noisy_latent")
        
        # Check if we have all required components
        if scheduler is None or timesteps is None or noisy_latents is None:
            device = pred_noise.device if isinstance(pred_noise, torch.Tensor) else torch.device("cpu")
            return torch.tensor(0.0, device=device), {}
        
        # Compute predicted clean latents from noisy latents and predicted noise
        device_obj = pred_noise.device
        alpha_bars = scheduler.alpha_bars.to(device_obj)
        alpha_bar = alpha_bars[timesteps].view(-1, 1, 1, 1)  # [B, 1, 1, 1]
        
        # Predict x0 from noisy latents: x0 = (x_t - sqrt(1 - alpha_bar) * epsilon) / sqrt(alpha_bar)
        pred_latents = (noisy_latents - (1 - alpha_bar).sqrt() * pred_noise) / alpha_bar.sqrt().clamp(min=1e-8)
        # Clamp to avoid numerical issues (use -6, 6 to match sampling clamping)
        pred_latents = torch.clamp(pred_latents, -6.0, 6.0)
        
        # Compute gradients on both predicted and ground-truth latents
        pred_gradients = self._compute_gradients(pred_latents)
        gt_gradients = self._compute_gradients(gt_latents)
        
        # Compute base structural loss (L1 difference between gradient magnitudes)
        # This preserves boundaries and transitions in latent space
        gradient_diff = torch.abs(pred_gradients - gt_gradients)
        
        # Apply SNR weighting: weight more at low noise (high alpha_bar) where pred_latents is more accurate
        # At high noise (low alpha_bar), pred_latents is expected to be noisy, so weight less
        snr = alpha_bar / (1 - alpha_bar + 1e-8)  # Signal-to-noise ratio
        snr_weight = snr / (1 + snr)  # SNR weighting (same as SNRWeightedNoiseLoss)
        # Higher weight when alpha_bar is high (low noise), lower when alpha_bar is low (high noise)
        
        if self.reduction == "mean":
            loss = (gradient_diff * snr_weight).mean() * self.weight
        else:  # sum
            loss = (gradient_diff * snr_weight).sum() / (pred_gradients.numel()) * self.weight
        
        return loss, {
            "latent_structural_loss": loss.detach(),
            f"latent_structural_{self.gradient_type}_pred_mean": pred_gradients.mean().detach(),
            f"latent_structural_{self.gradient_type}_gt_mean": gt_gradients.mean().detach(),
        }

