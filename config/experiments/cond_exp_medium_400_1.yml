# Conditioned Diffusion Experiment Configuration
# This file contains all parameters for conditional training with POV + Graph

experiment:
  exp_dir: /work3/s233249/ImgiNav/experiments/conditioned_diffusion_medium_cfg_001
  name: "Conditioned Diffusion (small) - POV + Graph - Run 001"
  description: "Training conditional diffusion with room POV and scene graphs"

# U-Net Configuration
unet:
  config_path: /work3/s233249/ImgiNav/ImgiNav/config/base_unet_medium_cond4.yml

# Noise Scheduler
scheduler:
  type: CosineScheduler  # LinearScheduler, CosineScheduler, SquaredCosineScheduler
  num_steps: 400


# Autoencoder (for generating samples during training)
autoencoder:
  config_path: /work3/s233249/ImgiNav/experiments/ae_configs/config_diff_4ch_64x64_vanilla.yml
  checkpoint_path: /work3/s233249/ImgiNav/experiments/autoencoder_final_64x64x4_vanila/20251004-082051_ae_final/best.pt

# Dataset - NOTE: Not used in conditioned version, uses manifests from CLI args instead
dataset:
  manifest_path: null  # Placeholder - room_manifest and scene_manifest passed via CLI

# Latent shape (C, H, W)
latent_shape: [4, 64, 64]


mixer:
  type: concat  # or 'weighted' or 'learned'
  pov_dim: 512
  graph_dim: 384


training:
  batch_size: 64
  num_epochs: 10
  learning_rate: 0.00001
  sample_every: 1
  num_samples: 8
  periodic_checkpoint_every: 5
  cfg:
    dropout_prob: 0.05        # reduce dropout for stronger conditioning signal
    guidance_scale: 7.0       # stronger guidance at sampling
