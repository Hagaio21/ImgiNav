# Conditioned Diffusion Experiment Configuration
# This file contains all parameters for conditional training with POV + Graph

experiment:
  exp_dir: /work3/s233249/ImgiNav/experiments/conditioned_diffusion_cfg_learned_mixer_NonLinear_002
  name: "Conditioned Diffusion - POV + Graph + mixer- Run 001"
  description: "Training conditional diffusion with room POV and scene graphs and learned mixer"

# Dataset - NOTE: Not used in conditioned version, uses manifests from CLI args instead
dataset:
  manifest_path: null  # Placeholder - room_manifest and scene_manifest passed via CLI
# Autoencoder (for generating samples during training)

autoencoder:
  config_path: /work3/s233249/ImgiNav/experiments/ae_configs/config_diff_4ch_64x64_vanilla.yml
  checkpoint_path: /work3/s233249/ImgiNav/experiments/autoencoder_final_64x64x4_vanila/20251004-082051_ae_final/best.pt

# U-Net Configuration
unet:
  config_path: /work3/s233249/ImgiNav/ImgiNav/config/architecture/cond_unet_small_condc8.yml




# Noise Scheduler
scheduler:
  type: CosineScheduler  # LinearScheduler, CosineScheduler, SquaredCosineScheduler
  num_steps: 200

# Latent shape (C, H, W)
latent_shape: [4, 64, 64]


mixer:
  type: NonLinearConcatMixer # Or LinearConcatMixer
  pov_dim: 512
  graph_dim: 384
  # Add specific settings here
  mlp_hidden_dim: 1024 # Example: Set hidden dim for NonLinear version
  # Add other settings if needed for future mixers


# Training Parameters
training:
  batch_size: 64
  num_epochs: 100
  learning_rate: 0.00001
  sample_every: 1
  periodic_checkpoint_every: 10
  
  cfg:
    dropout_prob: 0.1
    normalize_graph: False
    normalize_pov: False
    cond_scale_graph: 12.0
    cond_scale_pov: 1.0
    cond_scale_mix: 5.0
    
    log_condition_stats: True
    compute_corr_every: 300
    cond_clip_value: null
    guidance_scale: 7.5
