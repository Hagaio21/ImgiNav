# Conditioned Diffusion Experiment Configuration
# This file contains all parameters for conditional training with POV + Graph

experiment:
  exp_dir: /work3/s233249/ImgiNav/experiments/conditioned_diffusion_001
  name: "Conditioned Diffusion - POV + Graph - Run 001"
  description: "Training conditional diffusion with room POV and scene graphs"

# U-Net Configuration
unet:
  config_path: /work3/s233249/ImgiNav/ImgiNav/config/base_unet_medium_cond.yml

# Noise Scheduler
scheduler:
  type: CosineScheduler  # LinearScheduler, CosineScheduler, SquaredCosineScheduler
  num_steps: 500

# Autoencoder (for generating samples during training)
autoencoder:
  config_path: /work3/s233249/ImgiNav/experiments/ae_configs/config_diff_4ch_64x64_vanilla.yml
  checkpoint_path: /work3/s233249/ImgiNav/experiments/autoencoder_final_64x64x4_vanila/20251004-082051_ae_final/best.pt

# Dataset - NOTE: Not used in conditioned version, uses manifests from CLI args instead
dataset:
  manifest_path: null  # Placeholder - room_manifest and scene_manifest passed via CLI

# Latent shape (C, H, W)
latent_shape: [4, 64, 64]


mixer:
  type: concat  # or 'weighted' or 'learned'
  pov_dim: 512
  graph_dim: 384


# Training Parameters
training:
  batch_size: 32
  num_epochs: 200
  learning_rate: 0.00001
  sample_every: 5      # Generate samples every N epochs
  num_samples: 8       # Number of samples to generate (fixed for comparison)
  periodic_checkpoint_every: 10  # Save lightweight checkpoint every N epochs

