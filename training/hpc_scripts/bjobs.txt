
Job <26696939[1]>, Job Name <diffusion_sweep[1]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.1.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.1.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-14> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 3 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26696939[2]>, Job Name <diffusion_sweep[2]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.2.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.2.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-15> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 4 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26696939[3]>, Job Name <diffusion_sweep[3]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.3.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.3.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-15> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 4 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26696939[4]>, Job Name <diffusion_sweep[4]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.4.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.4.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-15> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 4 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26696939[5]>, Job Name <diffusion_sweep[5]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.5.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.5.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-15> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 4 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26696939[6]>, Job Name <diffusion_sweep[6]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpul40s>, Command <#!/bin
                          /bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s
                          233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diff
                          usion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav
                          /ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J
                          .%I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB
                           -gpu "num=1";#BSUB -W 24:00;#BSUB -q gpul40s; set -e
                          uo pipefail; # ======================================
                          =======================================;# PATHS;# ===
                          =====================================================
                          =====================;BASE_DIR="/work3/s233249/ImgiNa
                          v/ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_
                          diffusion.py";CONFIG_DIR="${BASE_DIR}/config/architec
                          ture/diffusion"; # Ordered list of YAMLs for uncondit
                          ioned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}
                          /E1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yam
                          l";  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG
                          _DIR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_
                          128.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); 
                          # Pick config for this array index;CONFIG_FILE="${CON
                          FIG_FILES[$((LSB_JOBINDEX-1))]}"; # =================
                          =====================================================
                          =======;# MODULES;# =================================
                          ============================================;module l
                          oad cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-
                          11.X;export MKL_INTERFACE_LAYER=LP64; # =============
                          =====================================================
                          ===========;# CONDA ENV;# ===========================
                          ==================================================;if
                           [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; th
                          en;  source "$HOME/miniconda3/etc/profile.d/conda.sh"
                          ;  conda activate imginav || {;    echo "Failed to ac
                          tivate conda environment 'imginav'" >&2;    conda act
                          ivate scenefactor || {;      echo "Failed to activate
                           any conda environment" >&2;      exit 1;    };  };fi
                          ; # =================================================
                          ============================;# RUN;# ================
                          =====================================================
                          ========;echo "======================================
                          ====";echo "Array job index: ${LSB_JOBINDEX}";echo "R
                          unning Diffusion experiment";echo "Config: ${CONFIG_F
                          ILE}";echo "Start: $(date)";echo "===================
                          ======================="; python "${PYTHON_SCRIPT}" -
                          -config "${CONFIG_FILE}"; echo "=====================
                          =====================";echo "Experiment COMPLETE";ech
                          o "End: $(date)";echo "==============================
                          ============">, Share group charged </s233249>, Esub 
                          <dcc>
Tue Oct 28 18:46:26 2025: Submitted from host <gbarlogin1>, CWD </work3/s233249
                          /ImgiNav/ImgiNav/training/hpc_scripts>, Output File <
                          /work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/l
                          ogs/diffusion_sweep.26696939.6.out>, Error File </wor
                          k3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/
                          diffusion_sweep.26696939.6.err>, 8 Task(s), Requested
                           Resources <rusage[mem=24000] span[hosts=1]>, Request
                          ed GPU <num=1>;
Tue Oct 28 18:46:27 2025: Reserved <8> job slots on host(s) <8*n-62-13-15> for 
                          <8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 4 ho
                          sts;

 RUNLIMIT                
 1440.0 min

 MEMLIMIT
   23.4 G 

 ESTIMATION:
Tue Oct 28 21:21:50 2025: Started simulation-based estimation;
Tue Oct 28 21:24:35 2025: Simulated job cannot start before <Tue Nov  4 21:21:5
                          0 2025>;

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	10385
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[1]>, Job Name <diffusion_sweep[1]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Share group charged </s233249>, Esub <d
                          cc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.1.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.1.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
Tue Oct 28 21:38:01 2025: Reserved <8> job slots on host(s) <8*n-62-18-5> for <
                          8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[2]>, Job Name <diffusion_sweep[2]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Share group charged </s233249>, Esub <d
                          cc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.2.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.2.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
Tue Oct 28 21:38:01 2025: Reserved <8> job slots on host(s) <8*n-62-18-5> for <
                          8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[3]>, Job Name <diffusion_sweep[3]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Share group charged </s233249>, Esub <d
                          cc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.3.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.3.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
Tue Oct 28 21:38:01 2025: Reserved <8> job slots on host(s) <8*n-62-18-5> for <
                          8> tasks;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[4]>, Job Name <diffusion_sweep[4]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Esub <dcc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.4.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.4.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[5]>, Job Name <diffusion_sweep[5]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Esub <dcc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.5.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.5.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -
------------------------------------------------------------------------------

Job <26697743[6]>, Job Name <diffusion_sweep[6]>, User <s233249>, Project <defa
                          ult>, Status <PEND>, Queue <gpua10>, Command <#!/bin/
                          bash;#BSUB -J diffusion_sweep[1-6];#BSUB -o /work3/s2
                          33249/ImgiNav/ImgiNav/training/hpc_scripts/logs/diffu
                          sion_sweep.%J.%I.out;#BSUB -e /work3/s233249/ImgiNav/
                          ImgiNav/training/hpc_scripts/logs/diffusion_sweep.%J.
                          %I.err;#BSUB -n 8;#BSUB -R "rusage[mem=24000]";#BSUB 
                          -gpu "num=1";#BSUB -W 12:00;#BSUB -q gpua10; set -euo
                           pipefail; # ========================================
                          =====================================;# PATHS;# =====
                          =====================================================
                          ===================;BASE_DIR="/work3/s233249/ImgiNav/
                          ImgiNav";PYTHON_SCRIPT="${BASE_DIR}/training/train_di
                          ffusion.py";CONFIG_DIR="${BASE_DIR}/config/architectu
                          re/diffusion"; # Ordered list of YAMLs for unconditio
                          ned diffusion sweep;CONFIG_FILES=(;  "${CONFIG_DIR}/E
                          1_Linear_64.yaml";  "${CONFIG_DIR}/E2_Cosine_64.yaml"
                          ;  "${CONFIG_DIR}/E3_Quadratic_64.yaml";  "${CONFIG_D
                          IR}/E4_Linear_128.yaml";  "${CONFIG_DIR}/E5_Cosine_12
                          8.yaml";  "${CONFIG_DIR}/E6_Quadratic_128.yaml";); # 
                          Pick config for this array index;CONFIG_FILE="${CONFI
                          G_FILES[$((LSB_JOBINDEX-1))]}"; # ===================
                          =====================================================
                          =====;# MODULES;# ===================================
                          ==========================================;module loa
                          d cuda/11.8;module load cudnn/v8.6.0.163-prod-cuda-11
                          .X;export MKL_INTERFACE_LAYER=LP64; # ===============
                          =====================================================
                          =========;# CONDA ENV;# =============================
                          ================================================;if [
                           -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
                          ;  source "$HOME/miniconda3/etc/profile.d/conda.sh"; 
                           conda activate imginav || {;    echo "Failed to acti
                          vate conda environment 'imginav'" >&2;    conda activ
                          ate scenefactor || {;      echo "Failed to activate a
                          ny conda environment" >&2;      exit 1;    };  };fi; 
                          # ===================================================
                          ==========================;# RUN;# ==================
                          =====================================================
                          ======;echo "========================================
                          ==";echo "Array job index: ${LSB_JOBINDEX}";echo "Run
                          ning Diffusion experiment";echo "Config: ${CONFIG_FIL
                          E}";echo "Start: $(date)";echo "=====================
                          ====================="; python "${PYTHON_SCRIPT}" --c
                          onfig "${CONFIG_FILE}"; echo "=======================
                          ===================";echo "Experiment COMPLETE";echo 
                          "End: $(date)";echo "================================
                          ==========">, Esub <dcc>
Tue Oct 28 21:38:01 2025: Submitted from host <n-62-30-6>, CWD </work3/s233249/
                          ImgiNav/ImgiNav/training/hpc_scripts>, Output File </
                          work3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/lo
                          gs/diffusion_sweep.26697743.6.out>, Error File </work
                          3/s233249/ImgiNav/ImgiNav/training/hpc_scripts/logs/d
                          iffusion_sweep.26697743.6.err>, 8 Task(s), Requested 
                          Resources <rusage[mem=24000] span[hosts=1]>, Requeste
                          d GPU <num=1>;
 PENDING REASONS:
 Job's requirements for reserving resource (ngpus_physical) not satisfied: 1 ho
                          st;

 RUNLIMIT                
 720.0 min

 MEMLIMIT
   23.4 G 

 PENDING TIME DETAILS:
 Eligible pending time (seconds):	90
 Ineligible pending time (seconds):	0

 SCHEDULING PARAMETERS:
           r15s   r1m  r15m   ut      pg    io   ls    it    tmp    swp    mem
 loadSched   -     -     -     -       -     -    -     -     -      -      -  
 loadStop    -     -     -     -       -     -    -     -     -      -      -  

 RESOURCE REQUIREMENT DETAILS:
 Job-level: rusage[mem=24000] span[hosts=1]
 App-level: -
 Queue-level: same[type:model] affinity[core] cu[type=enclosure:maxcus=1]
 Combined: select[(ngpus>0) && (type == local)] order[-slots:-maxslots] rusage[
                          mem=24000.00:ngpus_physical=1.00] span[hosts=1] same[
                          type:model] cu[pref=config:maxcus=1:type=enclosure] a
                          ffinity[core(1)*1]
 Effective: -

 GPU REQUIREMENT DETAILS:
 Combined: num=1:mode=exclusive_process:mps=no:j_exclusive=yes:aff=no:gvendor=n
                          vidia
 Effective: -

