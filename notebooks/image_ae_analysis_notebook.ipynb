{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Analysis of Autoencoder Performance (L1 + Cosine + PSNR/SSIM)\n",
    "\n",
    "This notebook analyzes the performance of different autoencoder models trained with varying latent and base channel configurations. We evaluate the models based on several metrics:\n",
    "\n",
    "* **L2 Distance (MSE):** Measures the pixel-wise squared error between the original and reconstructed images.\n",
    "* **Cosine Similarity:** Measures the similarity of the two image vectors.\n",
    "* **Peak Signal-to-Noise Ratio (PSNR):** Measures the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation. Higher is better.\n",
    "* **Structural Similarity Index (SSIM):** Measures the similarity between two images, considering luminance, contrast, and structure. Higher is better.\n",
    "\n",
    "The analysis consists of the following sections:\n",
    "1.  **Model and Dataset Definitions:** The core `Encoder`, `Decoder`, and `ImageDirectoryDataset` classes.\n",
    "2.  **Configuration and Data Loading:** Setting up paths, parameters, and loading the analysis dataset.\n",
    "3.  **Deep Analysis:** Iterating through trained models, generating reconstructions, and calculating the performance metrics.\n",
    "4.  **Quantitative Visualization:** Creating bar plots to compare the average performance of all models across all metrics.\n",
    "5.  **Qualitative Visualization:** Generating visual comparisons of original vs. reconstructed images for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: Core Imports and Definitions\n",
    "\n",
    "First, we import the necessary libraries. We'll use `torch` for model building and inference, `PIL` for image handling, `numpy` for numerical operations, and `matplotlib`/`seaborn` for plotting. We also import `psnr` and `ssim` from `skimage.metrics` for our new evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc389eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Analysis and Plotting Imports ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# --- Set a consistent plotting style ---\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Dataset Classes\n",
    "\n",
    "Here are the definitions for the `Encoder`, `Decoder`, and `ImageDirectoryDataset` classes. These are the same as in the training script to ensure that the model architecture is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.encode_decoder import Encoder, Decoder, ImageDirectoryDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: Configuration & Data Loading\n",
    "\n",
    "We define the configuration parameters for the analysis. This includes the project directory, the experiment group to analyze, the directory with the source images, and other parameters. We then create a `DataLoader` for the analysis images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROJECT_DIR = Path(\"C:/Users/Hagai.LAPTOP-QAG9263N/Desktop/Thesis/notebooks\")\n",
    "EXPERIMENT_GROUP = 'latent_sweep'\n",
    "SOURCE_DATA_DIR = BASE_PROJECT_DIR / \"recolored_images\"\n",
    "NUM_SAMPLES_TO_ANALYZE = 500\n",
    "BATCH_SIZE = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 1024\n",
    "CHECKPOINT_PATH = BASE_PROJECT_DIR / \"checkpoints\" / \"checkpoints\" / EXPERIMENT_GROUP\n",
    "PLOTS_DIR = BASE_PROJECT_DIR / \"plots\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Analyzing experiment group: '{EXPERIMENT_GROUP}'\")\n",
    "if not CHECKPOINT_PATH.exists():\n",
    "    print(f\"!!! FATAL ERROR: Checkpoint directory not found at {CHECKPOINT_PATH}\")\n",
    "    run_dirs = []\n",
    "else:\n",
    "    print(f\"Loading models from: {CHECKPOINT_PATH}\")\n",
    "    run_dirs = natsorted([d.name for d in CHECKPOINT_PATH.iterdir() if d.is_dir()])\n",
    "\n",
    "if not SOURCE_DATA_DIR.exists():\n",
    "    print(f\"!!! WARNING: Source data directory for analysis not found at {SOURCE_DATA_DIR}\")\n",
    "\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Plots will be saved to: {PLOTS_DIR}\")\n",
    "\n",
    "analysis_dataloader = None\n",
    "try:\n",
    "    all_files = [f.name for f in SOURCE_DATA_DIR.iterdir() if f.is_file() and f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"No images found in {SOURCE_DATA_DIR}\")\n",
    "    random.seed(42)\n",
    "    analysis_files = random.sample(all_files, min(len(all_files), NUM_SAMPLES_TO_ANALYZE))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    analysis_dataset = ImageDirectoryDataset(SOURCE_DATA_DIR, analysis_files, transform)\n",
    "    analysis_dataloader = DataLoader(analysis_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(f\"Created analysis dataset with {len(analysis_dataset)} images.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not create dataset. Please check the SOURCE_DATA_DIR path. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: Deep Analysis with L2, Cosine, PSNR, and SSIM\n",
    "\n",
    "This is the main analysis loop. For each model found in the checkpoints directory:\n",
    "1.  We parse the latent and base channels from the directory name.\n",
    "2.  We load the corresponding trained `Encoder` and `Decoder`.\n",
    "3.  We iterate through the analysis `DataLoader`, generate reconstructions for each image, and calculate L2 distance, Cosine Similarity, PSNR, and SSIM.\n",
    "4.  We store the average of these metrics for each model in a list.\n",
    "\n",
    "Finally, we create a Pandas DataFrame from the results for easy plotting and inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = []\n",
    "for run_name in tqdm(run_dirs, desc=\"Analyzing All Runs\"):\n",
    "    checkpoint_run_path = CHECKPOINT_PATH / run_name\n",
    "    encoder_path = checkpoint_run_path / \"encoder_final.pt\"\n",
    "    decoder_path = checkpoint_run_path / \"decoder_final.pt\"\n",
    "\n",
    "    if not encoder_path.exists() or not decoder_path.exists():\n",
    "        print(f\"Skipping '{run_name}': Missing 'encoder_final.pt' or 'decoder_final.pt'.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        match = re.search(r\"latent(\\d+)_base(\\d+)\", run_name)\n",
    "        if not match: raise ValueError(\"Directory name format is incorrect.\")\n",
    "        lc, bc = int(match.group(1)), int(match.group(2))\n",
    "    except (ValueError, IndexError):\n",
    "        print(f\"Skipping '{run_name}': Could not parse latent/base channels from name.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        encoder = Encoder(base_channels=bc, latent_channels=lc).to(DEVICE)\n",
    "        decoder = Decoder(base_channels=bc, latent_channels=lc).to(DEVICE)\n",
    "        encoder.load_state_dict(torch.load(encoder_path, map_location=DEVICE))\n",
    "        decoder.load_state_dict(torch.load(decoder_path, map_location=DEVICE))\n",
    "        encoder.eval(), decoder.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping '{run_name}': ARCHITECTURE MISMATCH or other loading error. Details: {e}\")\n",
    "        continue\n",
    "\n",
    "    all_l2, all_cosine, all_psnr, all_ssim = [], [], [], []\n",
    "    if analysis_dataloader:\n",
    "        with torch.no_grad():\n",
    "            for images in tqdm(analysis_dataloader, desc=f\"Run: base={bc}, lat={lc}\", leave=False):\n",
    "                images = images.to(DEVICE)\n",
    "                recon_images = decoder(encoder(images))\n",
    "                \n",
    "                # --- Metric Calculations ---\n",
    "                l2_dist = nn.functional.mse_loss(recon_images, images, reduction='none').mean(dim=[1,2,3])\n",
    "                cosine_sim = nn.functional.cosine_similarity(recon_images.view(images.size(0), -1), images.view(images.size(0), -1), dim=1)\n",
    "                all_l2.extend(l2_dist.cpu().numpy())\n",
    "                all_cosine.extend(cosine_sim.cpu().numpy())\n",
    "                \n",
    "                # For PSNR and SSIM, we need to un-normalize the images from [-1, 1] to [0, 1]\n",
    "                images_un = (images + 1) / 2\n",
    "                recon_images_un = (recon_images + 1) / 2\n",
    "                \n",
    "                for i in range(images.size(0)):\n",
    "                    img_orig = images_un[i].permute(1, 2, 0).cpu().numpy()\n",
    "                    img_recon = recon_images_un[i].permute(1, 2, 0).cpu().numpy()\n",
    "                    \n",
    "                    # Ensure pixel values are clipped to [0, 1] range for metrics\n",
    "                    img_orig = np.clip(img_orig, 0, 1)\n",
    "                    img_recon = np.clip(img_recon, 0, 1)\n",
    "\n",
    "                    psnr_val = peak_signal_noise_ratio(img_orig, img_recon, data_range=1.0)\n",
    "                    ssim_val = structural_similarity(img_orig, img_recon, multichannel=True, data_range=1.0, channel_axis=-1) # Use multichannel for RGB\n",
    "                    \n",
    "                    all_psnr.append(psnr_val)\n",
    "                    all_ssim.append(ssim_val)\n",
    "\n",
    "    if all_l2 and all_cosine:\n",
    "        analysis_results.append({\n",
    "            \"run_id\": run_name, \"base_channels\": bc, \"latent_channels\": lc,\n",
    "            \"avg_l2_distance\": np.mean(all_l2), \n",
    "            \"avg_cosine_similarity\": np.mean(all_cosine),\n",
    "            \"avg_psnr\": np.mean(all_psnr),\n",
    "            \"avg_ssim\": np.mean(all_ssim)\n",
    "        })\n",
    "\n",
    "df_analysis = pd.DataFrame(analysis_results)\n",
    "if not df_analysis.empty:\n",
    "    df_analysis = df_analysis.sort_values(by=[\"base_channels\", \"latent_channels\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")\n",
    "if not df_analysis.empty: \n",
    "    display(df_analysis)\n",
    "else: \n",
    "    print(\"No models were successfully analyzed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 4: Quantitative Visualization\n",
    "\n",
    "Now we create a 2x2 grid of bar plots to compare the performance of all models. Each plot represents one of our four metrics. This allows for a quick and easy comparison of the different model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_analysis.empty:\n",
    "    df_analysis['label'] = df_analysis.apply(\n",
    "        lambda row: f\"Latent={row['latent_channels']}\\n(Base={row['base_channels']})\", axis=1\n",
    "    )\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle('Autoencoder Performance Comparison', fontsize=24)\n",
    "\n",
    "    # L2 Distance Plot\n",
    "    sns.barplot(x=\"label\", y=\"avg_l2_distance\", data=df_analysis, ax=axes[0, 0], palette=\"plasma\")\n",
    "    axes[0, 0].set_title(\"Average L2 Distance (MSE)\", fontsize=16)\n",
    "    axes[0, 0].set_xlabel(\"Model Configuration\", fontsize=12)\n",
    "    axes[0, 0].set_ylabel(\"Average L2 Distance (Lower is Better)\", fontsize=12)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Cosine Similarity Plot\n",
    "    sns.barplot(x=\"label\", y=\"avg_cosine_similarity\", data=df_analysis, ax=axes[0, 1], palette=\"viridis\")\n",
    "    axes[0, 1].set_title(\"Average Cosine Similarity\", fontsize=16)\n",
    "    axes[0, 1].set_xlabel(\"Model Configuration\", fontsize=12)\n",
    "    axes[0, 1].set_ylabel(\"Average Cosine Similarity (Higher is Better)\", fontsize=12)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # PSNR Plot\n",
    "    sns.barplot(x=\"label\", y=\"avg_psnr\", data=df_analysis, ax=axes[1, 0], palette=\"cividis\")\n",
    "    axes[1, 0].set_title(\"Average Peak Signal-to-Noise Ratio (PSNR)\", fontsize=16)\n",
    "    axes[1, 0].set_xlabel(\"Model Configuration\", fontsize=12)\n",
    "    axes[1, 0].set_ylabel(\"Average PSNR (Higher is Better)\", fontsize=12)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # SSIM Plot\n",
    "    sns.barplot(x=\"label\", y=\"avg_ssim\", data=df_analysis, ax=axes[1, 1], palette=\"magma\")\n",
    "    axes[1, 1].set_title(\"Average Structural Similarity Index (SSIM)\", fontsize=16)\n",
    "    axes[1, 1].set_xlabel(\"Model Configuration\", fontsize=12)\n",
    "    axes[1, 1].set_ylabel(\"Average SSIM (Higher is Better)\", fontsize=12)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    save_path = PLOTS_DIR / f\"quantitative_comparison_{EXPERIMENT_GROUP}_with_psnr_ssim.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved quantitative comparison plot to: {save_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nAnalysis DataFrame is empty. Cannot generate quantitative plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 5: Qualitative Visualization\n",
    "\n",
    "Finally, we generate qualitative comparisons for each model. We select a few random sample images and for each model, we plot the original image next to its reconstruction. The title of the reconstruction now includes all four metrics (L2, Cosine Similarity, PSNR, and SSIM) to provide a complete picture of the model's performance on that specific image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_analysis.empty and analysis_dataloader:\n",
    "    NUM_VISUAL_SAMPLES = 4 # Show 4 samples per model\n",
    "    print(f\"\\nGenerating {len(df_analysis)} qualitative plots with {NUM_VISUAL_SAMPLES} samples each...\")\n",
    "\n",
    "    # Select 4 random sample images ONCE to use for all models for fair comparison\n",
    "    sample_indices = random.sample(range(len(analysis_dataset)), NUM_VISUAL_SAMPLES)\n",
    "    sample_images = torch.stack([analysis_dataset[i] for i in sample_indices]).to(DEVICE)\n",
    "\n",
    "    # Loop through each model in the analysis results\n",
    "    for idx, row in df_analysis.iterrows():\n",
    "        lc, bc = row['latent_channels'], row['base_channels']\n",
    "        run_id = row['run_id']\n",
    "        checkpoint_run_path = CHECKPOINT_PATH / run_id\n",
    "\n",
    "        fig, axes = plt.subplots(NUM_VISUAL_SAMPLES, 2, figsize=(12, 22))\n",
    "        fig.suptitle(f'Reconstruction Quality for Model: {run_id}\\n($C_{{base}}={bc}$, $C_{{lat}}={lc}$)', fontsize=18)\n",
    "\n",
    "        # Reload the specific model for this row\n",
    "        encoder = Encoder(base_channels=bc, latent_channels=lc).to(DEVICE)\n",
    "        decoder = Decoder(base_channels=bc, latent_channels=lc).to(DEVICE)\n",
    "        encoder.load_state_dict(torch.load(checkpoint_run_path / \"encoder_final.pt\", map_location=DEVICE))\n",
    "        decoder.load_state_dict(torch.load(checkpoint_run_path / \"decoder_final.pt\", map_location=DEVICE))\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            recon_samples = decoder(encoder(sample_images))\n",
    "\n",
    "        def prep_img(tensor_img):\n",
    "            return np.clip(tensor_img.permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "        for i in range(NUM_VISUAL_SAMPLES):\n",
    "            original, recon = sample_images[i], recon_samples[i]\n",
    "            \n",
    "            # Calculate metrics for this specific sample\n",
    "            l2 = nn.functional.mse_loss(recon, original).item()\n",
    "            cosine = nn.functional.cosine_similarity(recon.view(1, -1), original.view(1, -1)).item()\n",
    "            \n",
    "            original_un = (original + 1) / 2\n",
    "            recon_un = (recon + 1) / 2\n",
    "            img_orig_np = np.clip(original_un.permute(1, 2, 0).cpu().numpy(), 0, 1)\n",
    "            img_recon_np = np.clip(recon_un.permute(1, 2, 0).cpu().numpy(), 0, 1)\n",
    "            \n",
    "            psnr_val = peak_signal_noise_ratio(img_orig_np, img_recon_np, data_range=1.0)\n",
    "            ssim_val = structural_similarity(img_orig_np, img_recon_np, multichannel=True, data_range=1.0, channel_axis=-1)\n",
    "\n",
    "            axes[i, 0].imshow(prep_img(original))\n",
    "            axes[i, 0].set_title(f\"Original Sample #{i+1}\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            axes[i, 1].imshow(prep_img(recon))\n",
    "            axes[i, 1].set_title(f\"Reconstruction\\nL2: {l2:.4f} | CosSim: {cosine:.4f}\\nPSNR: {psnr_val:.2f} | SSIM: {ssim_val:.4f}\")\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        save_path = PLOTS_DIR / f\"qualitative_recon_{run_id}_with_psnr_ssim.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved qualitative plot to: {save_path}\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "else:\n",
    "    print(\"\\nAnalysis DataFrame is empty. Cannot generate qualitative comparisons.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
