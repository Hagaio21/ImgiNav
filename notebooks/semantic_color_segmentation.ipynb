{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Conversion Notebook for Semantic Scene Layouts\n",
    "\n",
    "This notebook provides a complete pipeline to recolor an existing dataset of scene layout images. It replaces the original colors with a new, semantically meaningful color scheme derived from text embeddings.\n",
    "\n",
    "### Workflow:\n",
    "1.  **Collect Labels**: Scan all `_tokens.json` files to gather a unique set of all object labels.\n",
    "2.  **Generate Semantic Colors**: Use a fine-tuned Sentence Transformer model to create embeddings for each label, then use PCA to map these embeddings to RGB colors. Labels with similar meanings will receive similar colors.\n",
    "3.  **Map Old to New**: Load the original `color_legend.json` to create a mapping from the old color values to the new semantic ones.\n",
    "4.  **Process Images**: Read each `.png` image, replace the old colors pixel by pixel with the new colors, and save the result to a new directory.\n",
    "\n",
    "**Hardcoded Colors:**\n",
    "* `floor`: Black (255, 255, 255)\n",
    "* `wall`: Black (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, this cell installs all the necessary libraries for the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy Pillow sentence-transformers scikit-learn tqdm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration\n",
    "\n",
    "This cell imports the required libraries and sets up the main configuration paths. Make sure the paths point to the correct directories in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm # Use notebook-friendly tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Imports and configuration loaded.\")\n",
    "\n",
    " # --- Configuration ---\n",
    "# Directory containing your original images and token files.\n",
    "INPUT_DIR = Path(\"output_pairs_old\")\n",
    "# Directory where the recolored images will be saved.\n",
    "OUTPUT_DIR = Path(\"recolored_images\")\n",
    "# Path to your original color legend.\n",
    "ORIGINAL_LEGEND_PATH = INPUT_DIR / \"color_legend.json\"\n",
    "# Path to the fine-tuned model you created in the embeddings_analysis notebook.\n",
    "FINETUNED_MODEL_PATH = './fine_tuned_bert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Definitions\n",
    "\n",
    "Here we define all the necessary functions for the color conversion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_labels(directory: Path) -> list:\n",
    "    \"\"\"Scans all *_tokens.json files to find unique furniture labels.\"\"\"\n",
    "    print(\"--- Collecting all unique labels from token files... ---\")\n",
    "    all_labels = set()\n",
    "    token_files = list(directory.glob(\"*_tokens.json\"))\n",
    "\n",
    "    if not token_files:\n",
    "        print(f\"[Warning] No token files found in '{directory}'.\")\n",
    "        return []\n",
    "        \n",
    "    for fname in tqdm(token_files, desc=\"Scanning labels\"):\n",
    "        try:\n",
    "            with open(fname, \"r\") as f:\n",
    "                tokens = json.load(f)\n",
    "            # A triplet is a list of 3 strings\n",
    "            triplets = [t for t in tokens if isinstance(t, list) and len(t) == 3]\n",
    "            for subj, _, obj in triplets:\n",
    "                # Add subject and object labels\n",
    "                if isinstance(subj, str): all_labels.add(subj)\n",
    "                if isinstance(obj, str): all_labels.add(obj)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            continue\n",
    "            \n",
    "    # Remove architectural elements that we will hardcode\n",
    "    all_labels.discard('wall')\n",
    "    all_labels.discard('floor')\n",
    "    \n",
    "    print(f\"Found {len(all_labels)} unique furniture labels.\")\n",
    "    return sorted(list(all_labels))\n",
    "\n",
    "def create_semantic_color_map(labels: list, model_path: str) -> dict:\n",
    "    \"\"\"Generates a new color map based on sentence transformer embeddings.\"\"\"\n",
    "    print(f\"... Generating semantic colors using '{model_path}'... ---\")\n",
    "    if not labels:\n",
    "        print(\"[Warning] No labels to process for color map generation.\")\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        model = SentenceTransformer(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Could not load model from '{model_path}'. Make sure the path is correct.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return {}\n",
    "\n",
    "    embeddings = model.encode(labels, show_progress_bar=True)\n",
    "    \n",
    "    # Reduce dimensionality from 384D to 3D for RGB mapping\n",
    "    pca = PCA(n_components=3)\n",
    "    components = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Normalize components to a 0-1 range\n",
    "    min_vals = components.min(axis=0)\n",
    "    max_vals = components.max(axis=0)\n",
    "    range_vals = max_vals - min_vals\n",
    "    # Avoid division by zero if all values in a component are the same\n",
    "    range_vals[range_vals == 0] = 1 \n",
    "    \n",
    "    normalized = (components - min_vals) / range_vals\n",
    "    rgb_values = (normalized * 255).astype(int)\n",
    "\n",
    "    # Create the label-to-color map\n",
    "    color_map = {label: tuple(rgb) for label, rgb in zip(labels, rgb_values)}\n",
    "    \n",
    "    # --- Apply Hardcoded Colors ---\n",
    "    color_map['wall'] = (0, 0, 0)      # Black\n",
    "    color_map['floor'] = (255, 255, 255)     # white!!!\n",
    "    \n",
    "    print(\"Semantic color map created successfully.\")\n",
    "    return color_map\n",
    "\n",
    "def create_recolor_map(original_legend_path: Path, new_color_map: dict) -> dict:\n",
    "    \"\"\"Creates a map from old RGB values to new RGB values.\"\"\"\n",
    "    print(\"--- Mapping old colors to new semantic colors... ---\")\n",
    "    try:\n",
    "        with open(original_legend_path, 'r') as f:\n",
    "            original_map = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[Error] Original color legend not found at '{original_legend_path}'. Cannot proceed.\")\n",
    "        return {}\n",
    "\n",
    "    recolor_map = {}\n",
    "    for label, new_color in new_color_map.items():\n",
    "        if label in original_map:\n",
    "            old_color = tuple(original_map[label])\n",
    "            recolor_map[old_color] = new_color\n",
    "            \n",
    "    print(f\"Created a mapping for {len(recolor_map)} colors.\")\n",
    "    return recolor_map\n",
    "\n",
    "def process_images(input_dir: Path, output_dir: Path, recolor_map: dict):\n",
    "    \"\"\"Applies the color conversion to all images in the directory.\"\"\"\n",
    "    print(\"--- Processing and recoloring images... ---\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    image_files = list(input_dir.glob(\"*.png\"))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"[Warning] No PNG images found in '{input_dir}'.\")\n",
    "        return\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Recoloring images\"):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            data = np.array(img)\n",
    "            \n",
    "            # Create a copy to modify\n",
    "            new_data = data.copy()\n",
    "\n",
    "            # Replace colors efficiently using numpy masks\n",
    "            for old_color, new_color in recolor_map.items():\n",
    "                mask = np.all(data == old_color, axis=-1)\n",
    "                new_data[mask] = new_color\n",
    "            \n",
    "            new_img = Image.fromarray(new_data)\n",
    "            new_img.save(output_dir / img_path.name)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process {img_path.name}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Execution\n",
    "\n",
    "This final cell runs the entire pipeline. It calls the functions defined above in sequence to perform the color conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Collecting all unique labels from token files... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10a6b230d774718b6250aa6fa552195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning labels:   0%|          | 0/1372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 598 unique furniture labels.\n",
      "... Generating semantic colors using './fine_tuned_bert'... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8dc2ad39694baa8b67bc4a229fc347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hagai.LAPTOP-QAG9263N\\.conda\\envs\\notebook-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic color map created successfully.\n",
      "New semantic color legend saved to 'recolored_images\\semantic_color_legend.json'\n",
      "--- Mapping old colors to new semantic colors... ---\n",
      "Created a mapping for 176 colors.\n",
      "--- Processing and recoloring images... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fafb7ab63624d6ca065ba227a583326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recoloring images:   0%|          | 0/1372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Done! All images have been recolored and saved in 'recolored_images'.\n"
     ]
    }
   ],
   "source": [
    "if not INPUT_DIR.exists():\n",
    "    print(f\"Error: Input directory '{INPUT_DIR}' not found. Please check the path.\")\n",
    "elif not ORIGINAL_LEGEND_PATH.exists():\n",
    "    print(f\"Error: The original 'color_legend.json' file is required but was not found in '{INPUT_DIR}'.\")\n",
    "else:\n",
    "    # Step 1: Collect labels\n",
    "    unique_labels = collect_all_labels(INPUT_DIR)\n",
    "    \n",
    "    # Step 2: Create the new semantic color map\n",
    "    semantic_map = create_semantic_color_map(unique_labels, FINETUNED_MODEL_PATH)\n",
    "    \n",
    "    if semantic_map:\n",
    "        # Save the new color legend for reference\n",
    "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        semantic_legend_path = OUTPUT_DIR / \"semantic_color_legend.json\"\n",
    "        with open(semantic_legend_path, 'w') as f:\n",
    "            # Convert numpy tuples to standard python tuples for JSON serialization\n",
    "            serializable_map = {k: [int(i) for i in v] for k, v in semantic_map.items()}\n",
    "            json.dump(serializable_map, f, indent=4)\n",
    "        print(f\"New semantic color legend saved to '{semantic_legend_path}'\")\n",
    "\n",
    "        # Step 3: Create the final old-to-new color mapping\n",
    "        final_recolor_map = create_recolor_map(ORIGINAL_LEGEND_PATH, semantic_map)\n",
    "\n",
    "        # Step 4: Process the images\n",
    "        if final_recolor_map:\n",
    "            process_images(INPUT_DIR, OUTPUT_DIR, final_recolor_map)\n",
    "            print(f\"\\n✨ Done! All images have been recolored and saved in '{OUTPUT_DIR}'.\")\n",
    "        else:\n",
    "            print(\"\\nCould not create a recolor map. Aborting image processing.\")\n",
    "    else:\n",
    "        print(\"\\nCould not create a semantic color map. Aborting.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
