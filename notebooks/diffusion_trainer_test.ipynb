{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Setup (run once)\n",
    "# ============================================================\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys, os\n",
    "sys.path.append(r\"C:\\Users\\Hagai.LAPTOP-QAG9263N\\Desktop\\Thesis\\repositories\\ImagiNav\")\n",
    "from modules.autoencoder import AutoEncoder\n",
    "from modules.unet import UNet\n",
    "from modules.diffusion import LatentDiffusion\n",
    "from modules.scheduler import CosineScheduler\n",
    "from training.diffusion_trainer import DiffusionTrainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 2. Dummy dataset\n",
    "# ============================================================\n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, length=32, shape=(3, 64, 64)):\n",
    "        self.length = length\n",
    "        self.shape = shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return tuple to preserve batch dimension\n",
    "        return (torch.zeros(self.shape),)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(DummyDataset(length=16), batch_size=4)\n",
    "val_loader = DataLoader(DummyDataset(length=8), batch_size=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7501ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Instantiate components (aligned latent AE + UNet)\n",
    "# ============================================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define shared latent geometry for AE and UNet\n",
    "latent_channels = 3\n",
    "latent_base = 16\n",
    "image_size = 64\n",
    "\n",
    "# Autoencoder built via new from_shape API\n",
    "autoencoder = AutoEncoder.from_shape(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    base_channels=16,\n",
    "    latent_channels=latent_channels,\n",
    "    image_size=image_size,\n",
    "    latent_base=latent_base,\n",
    "    norm=\"batch\",\n",
    "    act=\"relu\"\n",
    ").to(device)\n",
    "\n",
    "# UNet configured to operate on the same latent space\n",
    "unet = UNet(\n",
    "    in_channels=latent_channels,\n",
    "    out_channels=latent_channels,\n",
    "    base_channels=16,\n",
    "    depth=3\n",
    ").to(device)\n",
    "\n",
    "scheduler = CosineScheduler(num_steps=10)\n",
    "latent_diffusion = LatentDiffusion(unet, scheduler, autoencoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = DiffusionTrainer(\n",
    "    unet=unet,\n",
    "    autoencoder=autoencoder,\n",
    "    scheduler=scheduler,\n",
    "    epochs=10,\n",
    "    log_interval=1,       # log every step\n",
    "    sample_interval=2,    # create artifacts every 2 steps\n",
    "    eval_interval=4,\n",
    "    output_dir=\"test_outputs\",\n",
    "    ckpt_dir=\"test_outputs/checkpoints\",\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Run one short training cycle\n",
    "# ============================================================\n",
    "trainer.fit(train_loader, val_loader)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Inspect results\n",
    "# ============================================================\n",
    "print(\"\\nTraining complete.\")\n",
    "print(\"Artifacts saved in:\", os.path.abspath(trainer.output_dir))\n",
    "print(\"Metric log entries:\", len(getattr(trainer, 'metric_log', [])))\n",
    "\n",
    "# Display one sample of recorded metrics (if available)\n",
    "if hasattr(trainer, \"metric_log\") and trainer.metric_log:\n",
    "    print(\"Example metrics:\", trainer.metric_log[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImgiNav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
