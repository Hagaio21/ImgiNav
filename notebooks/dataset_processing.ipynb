{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation Notebook\n",
    "This notebook loads 3D-FRONT scenes, generates accurate semantic point clouds and color-coded 2D top-down layout maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Imports and Setup**\n",
    "\n",
    "This first cell imports all the necessary libraries for the script. It includes standard libraries like `os` and `json`, data manipulation libraries like `numpy`, 3D processing with `trimesh`, and image handling with `PIL` (Pillow). Notably, `matplotlib` is configured with a non-interactive 'Agg' backend, which is essential for running the script in environments without a graphical user interface, such as a remote server or a Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm  # Use notebook-friendly tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib and set backend for headless operation\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Use a non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union, List, Dict, Any, Tuple\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **2. Configuration**\n",
    "\n",
    "Instead of using command-line arguments, you can set all the necessary paths and options here. The script can auto-detect the model directory and info file, but you can also specify them manually for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Configuration ---\n",
    "# Set the output directory for generated pairs.\n",
    "OUTPUT_PATH = Path(\"output_pairs\")\n",
    "\n",
    "# Run in headless mode (suppresses verbose logs). Set to False for detailed output.\n",
    "HEADLESS_MODE = False\n",
    "\n",
    "# --- Path Configuration ---\n",
    "# The JSON file listing valid scenes to process.\n",
    "# This file should be generated by a prior validation script.\n",
    "SCENES_FILE_PATH = Path(\"valid_scenes.json\")\n",
    "\n",
    "# --- Optional: Manually specify dataset paths ---\n",
    "# If you leave these as None, the script will try to auto-detect them.\n",
    "# Otherwise, provide the full path to the required directory/file.\n",
    "MANUAL_MODEL_DIR = None   # e.g., Path(\"/path/to/your/3D-FUTURE-model\")\n",
    "MANUAL_MODEL_INFO = None  # e.g., Path(\"/path/to/your/model_info.json\")\n",
    "\n",
    "# --- Slicing Parameters ---\n",
    "# The height (Z-axis) where the cross-section slice begins.\n",
    "SLICE_Z_POSITION = 0.1\n",
    "# The thickness of the cross-section slice for walls.\n",
    "SLICE_THICKNESS = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **3. Path Setup Function**\n",
    "\n",
    "The `setup_paths` function is responsible for finding and validating the necessary dataset directories and files. It prioritizes any manually set paths from the configuration cell above. If no manual paths are provided, it attempts to automatically locate the `3D-FUTURE-model` directory and the `model_info.json` file by searching up from the current working directory. This makes the notebook more portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(model_dir_arg: Path = None, model_info_arg: Path = None) -> Tuple[Path, Path]:\n",
    "    \"\"\"\n",
    "    Sets up and validates necessary dataset paths.\n",
    "    Prioritizes user-provided arguments, otherwise auto-detects.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. SETTING UP PATHS ---\")\n",
    "    \n",
    "    # --- Determine Model Directory ---\n",
    "    model_dir_candidate = None\n",
    "    if model_dir_arg:\n",
    "        print(f\"Using provided model directory path: {model_dir_arg}\")\n",
    "        assert model_dir_arg.is_dir(), f\"Provided model directory not found: {model_dir_arg}\"\n",
    "        MODEL_DIR = model_dir_arg\n",
    "        model_dir_candidate = MODEL_DIR\n",
    "    else:\n",
    "        print(\"Auto-detecting model directory...\")\n",
    "        current_path = Path.cwd()\n",
    "        for _ in range(4): # Search up to 4 levels\n",
    "            candidate = next(current_path.glob(\"**/3D-FUTURE-model\"), None)\n",
    "            if candidate:\n",
    "                model_dir_candidate = candidate\n",
    "                break\n",
    "            current_path = current_path.parent\n",
    "        \n",
    "        if not model_dir_candidate:\n",
    "            raise FileNotFoundError(\"Could not auto-detect '3D-FUTURE-model' directory.\")\n",
    "\n",
    "        if (model_dir_candidate / \"3D-FUTURE-model\").is_dir():\n",
    "            MODEL_DIR = model_dir_candidate / \"3D-FUTURE-model\"\n",
    "        else:\n",
    "            MODEL_DIR = model_dir_candidate\n",
    "        print(f\"Found model directory at: {MODEL_DIR}\")\n",
    "\n",
    "    # --- Determine Model Info File ---\n",
    "    if model_info_arg:\n",
    "        print(f\"Using provided model info file path: {model_info_arg}\")\n",
    "        assert model_info_arg.is_file(), f\"Provided model info file not found: {model_info_arg}\"\n",
    "        MODEL_INFO_FILE = model_info_arg\n",
    "    else:\n",
    "        print(\"Auto-detecting model info file...\")\n",
    "        assert model_dir_candidate is not None, \"Cannot search for model_info.json without a model directory.\"\n",
    "        MODEL_INFO_FILE = next(model_dir_candidate.glob(\"**/model_info.json\"), None)\n",
    "        if not MODEL_INFO_FILE:\n",
    "            raise FileNotFoundError(f\"Could not auto-detect 'model_info.json' within or near {model_dir_candidate}\")\n",
    "        print(f\"Found model info file at: {MODEL_INFO_FILE}\")\n",
    "\n",
    "    print(\"✅ Dataset paths have been validated successfully.\")\n",
    "    return MODEL_DIR, MODEL_INFO_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **4. Helper Functions**\n",
    "\n",
    "These are small utility functions used throughout the script.\n",
    "* `get_dominant_direction`: Calculates the primary spatial relationship (e.g., \"is above\", \"is to the East of\") between two points.\n",
    "* `get_final_label`: Determines the most reliable category label for a piece of furniture, checking both the model info file and the scene's item data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_direction(vector: np.ndarray) -> str:\n",
    "    \"\"\"Determines the main cardinal or vertical direction of a vector.\"\"\"\n",
    "    if np.linalg.norm(vector) < 0.1: return \"is co-located with\"\n",
    "    dx, dy, dz = vector\n",
    "    abs_x, abs_y, abs_z = abs(dx), abs(dy), abs(dz)\n",
    "    if abs_y > abs_x and abs_y > abs_z:\n",
    "        return \"is above\" if dy > 0 else \"is below\"\n",
    "    elif abs_x > abs_z:\n",
    "        return \"is to the East of\" if dx > 0 else \"is to the West of\"\n",
    "    else:\n",
    "        return \"is to the South of\" if dz > 0 else \"is to the North of\"\n",
    "\n",
    "def get_final_label(item: Dict, model_info_map: Dict) -> Union[str, None]:\n",
    "    \"\"\"Determines an object's definitive label using the validation script's logic.\"\"\"\n",
    "    jid = item.get('jid')\n",
    "    label = model_info_map.get(jid, {}).get('category')\n",
    "    if not label or label in ['None', 'Unknown']:\n",
    "        label = item.get('title')\n",
    "\n",
    "    if label and isinstance(label, str) and label.strip():\n",
    "        return label.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **5. Core Logic: Image Generation**\n",
    "\n",
    "The `generate_sliced_layout_render` function is the heart of the image creation process. It performs several key steps:\n",
    "1.  **Load Geometry**: It loads all meshes (furniture, walls, floors) from a scene's metadata.\n",
    "2.  **Orient Scene**: It calculates a transformation matrix to align the scene to a consistent top-down view, primarily by analyzing the floor's normal vector.\n",
    "3.  **Slice Walls**: It converts all meshes into a colored point cloud. Critically, it only keeps points from the **wall** meshes that fall within a specific vertical slice (defined by `SLICE_Z_POSITION` and `SLICE_THICKNESS`). All furniture and floor points are kept.\n",
    "4.  **Render Image**: It projects the final, filtered point cloud onto a 2D canvas, creating a top-down layout image where walls appear as a cross-section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliced_layout_render(scene_metadata: Dict, model_dir: Path, model_info_map: Dict, color_map: Dict, slice_z_position: float, slice_thickness: float, headless: bool = False) -> Tuple[Union[Image.Image, None], Union[np.ndarray, None]]:\n",
    "    \"\"\"Creates a colored 2D render where walls are sliced, using a consistent color map.\"\"\"\n",
    "    if not headless: print(\"  ▶️ Starting Sliced Layout Generation...\")\n",
    "    \n",
    "    # 1. Load and Orient all 3D Meshes\n",
    "    all_meshes_to_process = []\n",
    "    furniture_info_map = {f['uid']: f for f in scene_metadata.get('furniture', [])}\n",
    "    mesh_uid_map = {m['uid']: m for m in scene_metadata.get('mesh', [])}\n",
    "    rooms = scene_metadata.get(\"scene\", {}).get(\"room\", [])\n",
    "    if not rooms: return None, np.eye(4)\n",
    "\n",
    "    for room_data in rooms:\n",
    "        for child in room_data.get(\"children\", []):\n",
    "            ref_uid = child.get(\"ref\")\n",
    "            if not ref_uid: continue\n",
    "\n",
    "            try:\n",
    "                mesh, mesh_type, label = (None, 'misc', None)\n",
    "                if ref_uid in furniture_info_map:\n",
    "                    item_info = furniture_info_map[ref_uid]\n",
    "                    jid = item_info.get('jid')\n",
    "                    if not jid: continue\n",
    "                    label = get_final_label(item_info, model_info_map)\n",
    "                    if not label: continue\n",
    "                    model_path = model_dir / jid / \"raw_model.obj\"\n",
    "                    if not model_path.exists(): continue\n",
    "                    mesh, mesh_type = trimesh.load(model_path, force='mesh', process=False), 'furniture'\n",
    "                elif ref_uid in mesh_uid_map:\n",
    "                    mesh_data = mesh_uid_map[ref_uid]\n",
    "                    if 'Ceiling' in mesh_data.get(\"type\", \"\"): continue\n",
    "                    vertices = np.array(mesh_data[\"xyz\"], dtype=np.float32).reshape(-1, 3)\n",
    "                    faces = np.array(mesh_data[\"faces\"], dtype=np.int32).reshape(-1, 3)\n",
    "                    mesh, mesh_type = trimesh.Trimesh(vertices=vertices, faces=faces, process=False), 'floor' if 'Floor' in mesh_data.get(\"type\", \"\") else 'wall'\n",
    "                    label = mesh_type\n",
    "\n",
    "                if not mesh or mesh.is_empty: continue\n",
    "\n",
    "                transform = np.eye(4)\n",
    "                transform[:3, 3] = child.get(\"pos\", [0, 0, 0])\n",
    "                transform[:3, :3] = Rotation.from_quat(child.get(\"rot\", [0, 0, 0, 1])).as_matrix()\n",
    "                mesh.apply_transform(transform)\n",
    "                mesh.apply_scale(child.get(\"scale\", [1, 1, 1]))\n",
    "                all_meshes_to_process.append({'mesh': mesh, 'type': mesh_type, 'label': label})\n",
    "            except Exception as e:\n",
    "                print(f\"      ❗️ ERROR loading item {ref_uid}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if not all_meshes_to_process:\n",
    "        print(\"      ⚠️ No valid geometry was loaded for the scene.\")\n",
    "        return None, np.eye(4)\n",
    "\n",
    "    # Orient scene to top-down view\n",
    "    rotation_matrix = np.eye(4)\n",
    "    floor_meshes = [item['mesh'] for item in all_meshes_to_process if item['type'] == 'floor']\n",
    "    if floor_meshes:\n",
    "        combined_floor = trimesh.util.concatenate(floor_meshes)\n",
    "        if not combined_floor.is_empty:\n",
    "            floor_normal = combined_floor.face_normals[np.argmax(combined_floor.area_faces)]\n",
    "            if floor_normal[2] < 0: floor_normal *= -1\n",
    "            rotation_matrix = trimesh.geometry.align_vectors(floor_normal, [0, 0, 1])\n",
    "            for item in all_meshes_to_process:\n",
    "                item['mesh'].apply_transform(rotation_matrix)\n",
    "\n",
    "    # 2. Generate Full 3D Point Cloud with Consistent Colors\n",
    "    meshes_to_render = [item['mesh'] for item in all_meshes_to_process]\n",
    "    mesh_props = [{'type': item['type'], 'label': item['label']} for item in all_meshes_to_process]\n",
    "    default_color = (128, 128, 128)\n",
    "    mesh_colors_list = [color_map.get(item['label'], default_color) for item in mesh_props]\n",
    "    \n",
    "    full_scene_mesh = trimesh.util.concatenate(meshes_to_render)\n",
    "    face_counts_cumulative = np.cumsum([len(m.faces) for m in meshes_to_render])\n",
    "    points, face_indices = trimesh.sample.sample_surface(full_scene_mesh, 1_500_000)\n",
    "    source_mesh_indices = np.searchsorted(face_counts_cumulative, face_indices, side='right')\n",
    "    point_colors = np.array([mesh_colors_list[i] for i in source_mesh_indices])\n",
    "    point_types = np.array([mesh_props[i]['type'] for i in source_mesh_indices])\n",
    "\n",
    "    # 3. Filter Wall Points to Keep Only the Slice Band\n",
    "    is_wall_mask = (point_types == 'wall')\n",
    "    wall_points_z = points[is_wall_mask, 2]\n",
    "    in_band_mask = (wall_points_z >= slice_z_position) & (wall_points_z <= slice_z_position + slice_thickness)\n",
    "    wall_points_in_band_full_mask = np.zeros(len(points), dtype=bool)\n",
    "    wall_points_in_band_full_mask[is_wall_mask] = in_band_mask\n",
    "    final_keep_mask = ~is_wall_mask | wall_points_in_band_full_mask\n",
    "    final_points, final_colors = points[final_keep_mask], point_colors[final_keep_mask]\n",
    "\n",
    "    # 4. Project and Render the Final Image\n",
    "    sort_order = np.argsort(final_points[:, 2])\n",
    "    sorted_points, sorted_colors = final_points[sort_order], final_colors[sort_order]\n",
    "    xy_coords = sorted_points[:, :2]\n",
    "    min_coords, max_coords = points[:, :2].min(axis=0), points[:, :2].max(axis=0)\n",
    "    img_size_px, point_radius = 1024, 2\n",
    "    scale = img_size_px / max(1e-6, (max_coords - min_coords).max())\n",
    "    img_shape = (np.ceil((max_coords - min_coords) * scale).astype(int) + 4)[::-1]\n",
    "    \n",
    "    canvas = Image.new('RGB', (img_shape[1], img_shape[0]), 'white')\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    pixel_coords = np.round((xy_coords - min_coords) * scale).astype(int) + 2\n",
    "    pixel_coords[:, 1] = img_shape[0] - 1 - pixel_coords[:, 1]\n",
    "\n",
    "    for i in range(len(pixel_coords)):\n",
    "        px, py = pixel_coords[i]\n",
    "        draw.rectangle([px - point_radius, py - point_radius, px + point_radius, py + point_radius], fill=tuple(sorted_colors[i]))\n",
    "\n",
    "    if not headless: print(\"  ✅ Image Generation Complete.\")\n",
    "    return canvas, rotation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **6. Core Logic: Scene Graph Tokenization**\n",
    "\n",
    "This function, `generate_scene_graph_tokens`, complements the image generation by creating a structured, textual description of the scene. It identifies all furniture within each room and generates a \"scene graph\" composed of relationship triplets:\n",
    "* **Intra-room relationships**: Describes how objects are positioned relative to each other within the same room (e.g., `(sofa, is to the West of, end_table)`).\n",
    "* **Inter-room relationships**: Describes how rooms are positioned relative to each other based on their centroids (e.g., `(LivingRoom, is to the North of, Bedroom)`).\n",
    "* **Containment**: Explicitly states which objects are in which room (e.g., `(sofa, is_in, LivingRoom)`).\n",
    "\n",
    "The final output is a list of these tokens, enclosed by special `[SCENE_START]` and `[SCENE_END]` markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scene_graph_tokens(scene_data: Dict, model_info_map: Dict, rotation_matrix: np.ndarray, headless: bool = False) -> List[Any]:\n",
    "    \"\"\"Generates a tokenized scene graph with spatial relationships.\"\"\"\n",
    "    if not headless: print(\"  ▶️ Starting Token Generation...\")\n",
    "    \n",
    "    furniture_details_map = {item['uid']: item for item in scene_data.get('furniture', [])}\n",
    "    all_rooms = scene_data.get(\"scene\", {}).get(\"room\", [])\n",
    "    valid_rooms = []\n",
    "    \n",
    "    # Filter for rooms that contain valid, labeled furniture\n",
    "    for i, room in enumerate(all_rooms):\n",
    "        furniture_in_room = []\n",
    "        for child in room.get('children', []):\n",
    "            ref_id = child.get('ref')\n",
    "            if 'pos' in child and ref_id and ref_id in furniture_details_map:\n",
    "                item_info = furniture_details_map[ref_id]\n",
    "                final_label = get_final_label(item_info, model_info_map)\n",
    "                if final_label:\n",
    "                    furniture_in_room.append({'pos': np.array(child['pos']), 'label': final_label})\n",
    "        if furniture_in_room:\n",
    "            valid_rooms.append({\"id\": i, \"type\": room.get('type', 'Unknown'), \"furniture\": furniture_in_room})\n",
    "\n",
    "    if not valid_rooms: return []\n",
    "    if not headless: print(f\"      - Found {len(valid_rooms)} rooms with furniture to tokenize.\")\n",
    "\n",
    "    tokenized_scene = {\"inter_room_relationships\": [], \"rooms\": []}\n",
    "    valid_room_centroids = []\n",
    "    \n",
    "    # Process intra-room relationships\n",
    "    for room_data in valid_rooms:\n",
    "        current_room_tokens = {\"room_id\": room_data[\"id\"], \"room_type\": room_data[\"type\"], \"furniture\": [item['label'] for item in room_data[\"furniture\"]], \"intra_room_relationships\": []}\n",
    "        furniture_list = room_data[\"furniture\"]\n",
    "        positions = np.array([f['pos'] for f in furniture_list])\n",
    "        if len(furniture_list) > 1:\n",
    "            for item1, item2 in itertools.combinations(furniture_list, 2):\n",
    "                relationship = get_dominant_direction(item2['pos'] - item1['pos'])\n",
    "                token = (item2['label'], relationship, item1['label'])\n",
    "                current_room_tokens[\"intra_room_relationships\"].append(token)\n",
    "        tokenized_scene[\"rooms\"].append(current_room_tokens)\n",
    "        centroid = np.mean(positions, axis=0)\n",
    "        rotated_centroid = trimesh.transform_points(centroid.reshape(1, -1), rotation_matrix)[0]\n",
    "        valid_room_centroids.append({'id': room_data[\"id\"], 'type': room_data[\"type\"], 'centroid': rotated_centroid})\n",
    "    \n",
    "    # Process inter-room relationships\n",
    "    if len(valid_room_centroids) > 1:\n",
    "        for room1, room2 in itertools.combinations(valid_room_centroids, 2):\n",
    "            relationship = get_dominant_direction(room2['centroid'] - room1['centroid'])\n",
    "            token = (f\"Room{room2['id']}_{room2['type']}\", relationship, f\"Room{room1['id']}_{room1['type']}\")\n",
    "            tokenized_scene[\"inter_room_relationships\"].append(token)\n",
    "\n",
    "    # Assemble final token list\n",
    "    advanced_tokens = [\"[SCENE_START]\"]\n",
    "    for room_data in tokenized_scene.get(\"rooms\", []):\n",
    "        advanced_tokens.append(\"[ROOM_START]\")\n",
    "        room_name = f\"Room{room_data['room_id']}_{room_data['room_type']}\"\n",
    "        for furniture_item in room_data.get(\"furniture\", []):\n",
    "            advanced_tokens.append((furniture_item, \"is_in\", room_name))\n",
    "        for triplet in room_data.get(\"intra_room_relationships\", []):\n",
    "            advanced_tokens.append(triplet)\n",
    "        advanced_tokens.append(\"[ROOM_END]\")\n",
    "    for triplet in tokenized_scene.get(\"inter_room_relationships\", []):\n",
    "        advanced_tokens.append(triplet)\n",
    "    advanced_tokens.append(\"[SCENE_END]\")\n",
    "    \n",
    "    if not headless: print(f\"  ✅ Token Generation Complete ({len(advanced_tokens)} tokens).\")\n",
    "    return advanced_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **7. Main Execution**\n",
    "\n",
    "This final cell orchestrates the entire process.\n",
    "1.  **Setup**: It calls `setup_paths` to initialize and validate all file paths. It then loads the `model_info.json` metadata and the list of scenes to process.\n",
    "2.  **Color Map Generation**: It pre-scans all scenes to find every unique furniture label. It then creates a consistent, deterministic color map for all labels, ensuring that, for example, a \"sofa\" is the same color in every generated image. This color legend is saved to a JSON file.\n",
    "3.  **Processing Loop**: It iterates through each validated scene. For each one, it calls `generate_sliced_layout_render` to create the image and `generate_scene_graph_tokens` to create the textual description. If both are successful, it saves the image (`.png`) and the tokens (`.json`) as a pair in the specified output directory.\n",
    "\n",
    "A progress bar from `tqdm` provides feedback on the overall progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. SETTING UP PATHS ---\n",
      "Auto-detecting model directory...\n",
      "Found model directory at: c:\\Users\\Hagai.LAPTOP-QAG9263N\\Desktop\\Thesis\\datasets\\3D-FRONT_FUTURE\\3D-FUTURE-model\\3D-FUTURE-model\n",
      "Auto-detecting model info file...\n",
      "Found model info file at: c:\\Users\\Hagai.LAPTOP-QAG9263N\\Desktop\\Thesis\\datasets\\3D-FRONT_FUTURE\\3D-FUTURE-model\\model_info.json\n",
      "✅ Dataset paths have been validated successfully.\n",
      "\n",
      "--- 2. LOADING METADATA AND SETTING UP OUTPUT ---\n",
      "Loaded metadata for 16563 models.\n",
      "Loaded a list of 4843 scenes to process from 'valid_scenes.json'.\n",
      "✅ Output will be saved to: output_pairs\n",
      "\n",
      "--- 3. PRE-SCANNING SCENES FOR CONSISTENT COLOR SCHEME ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ae02bb26f44a8cb9a2c4d98e1516d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning for categories:   0%|          | 0/4843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a consistent color map for 282 categories.\n",
      "✅ Saved color legend to 'output_pairs\\color_legend.json'\n",
      "\n",
      "--- 4. PROCESSING SCENES AND GENERATING PAIRS ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6fa19610a4485285f75a8b850c470e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating pairs:   0%|          | 0/4843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00004f89-9aa5-43c2-ae3c-129586be8aaa\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (211 tokens).\n",
      "  💾 Saved pair: 00004f89-9aa5-43c2-ae3c-129586be8aaa_image.png, 00004f89-9aa5-43c2-ae3c-129586be8aaa_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0003d406-5f27-4bbf-94cd-1cff7c310ba1\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (627 tokens).\n",
      "  💾 Saved pair: 0003d406-5f27-4bbf-94cd-1cff7c310ba1_image.png, 0003d406-5f27-4bbf-94cd-1cff7c310ba1_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00154c06-2ee2-408a-9664-b8fd74742897\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (298 tokens).\n",
      "  💾 Saved pair: 00154c06-2ee2-408a-9664-b8fd74742897_image.png, 00154c06-2ee2-408a-9664-b8fd74742897_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0018b6c8-c3b6-4fb8-a640-4b9b0b763254\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (404 tokens).\n",
      "  💾 Saved pair: 0018b6c8-c3b6-4fb8-a640-4b9b0b763254_image.png, 0018b6c8-c3b6-4fb8-a640-4b9b0b763254_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0023b7d1-1439-4e5c-9c7b-c34f155ee856\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (244 tokens).\n",
      "  💾 Saved pair: 0023b7d1-1439-4e5c-9c7b-c34f155ee856_image.png, 0023b7d1-1439-4e5c-9c7b-c34f155ee856_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 002c110c-9bbc-4ab4-affa-4225fb127bad\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 11 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (579 tokens).\n",
      "  💾 Saved pair: 002c110c-9bbc-4ab4-affa-4225fb127bad_image.png, 002c110c-9bbc-4ab4-affa-4225fb127bad_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00321452-517d-431b-a21b-f52750684910\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (305 tokens).\n",
      "  💾 Saved pair: 00321452-517d-431b-a21b-f52750684910_image.png, 00321452-517d-431b-a21b-f52750684910_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00337f71-5f56-4d82-8848-b8d194a27d4e\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (69 tokens).\n",
      "  💾 Saved pair: 00337f71-5f56-4d82-8848-b8d194a27d4e_image.png, 00337f71-5f56-4d82-8848-b8d194a27d4e_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 003ac11d-2abc-44f8-9836-4354e7dfa543\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (460 tokens).\n",
      "  💾 Saved pair: 003ac11d-2abc-44f8-9836-4354e7dfa543_image.png, 003ac11d-2abc-44f8-9836-4354e7dfa543_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 004f900c-468a-4f70-83cc-aa2c98875264\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (406 tokens).\n",
      "  💾 Saved pair: 004f900c-468a-4f70-83cc-aa2c98875264_image.png, 004f900c-468a-4f70-83cc-aa2c98875264_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0054adcb-f48f-4d52-b198-321fd078caa4\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (249 tokens).\n",
      "  💾 Saved pair: 0054adcb-f48f-4d52-b198-321fd078caa4_image.png, 0054adcb-f48f-4d52-b198-321fd078caa4_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00593e46-062e-4bdd-8ee9-1043387c40f4\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (425 tokens).\n",
      "  💾 Saved pair: 00593e46-062e-4bdd-8ee9-1043387c40f4_image.png, 00593e46-062e-4bdd-8ee9-1043387c40f4_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0071b16d-ed1c-498f-9fd6-74e3f8aa2fb6\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 3 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (118 tokens).\n",
      "  💾 Saved pair: 0071b16d-ed1c-498f-9fd6-74e3f8aa2fb6_image.png, 0071b16d-ed1c-498f-9fd6-74e3f8aa2fb6_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0071fae9-a2ce-481e-8a37-a2d307e1213d\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 10 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (545 tokens).\n",
      "  💾 Saved pair: 0071fae9-a2ce-481e-8a37-a2d307e1213d_image.png, 0071fae9-a2ce-481e-8a37-a2d307e1213d_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00766588-c1d9-4039-ba22-a7e037c929b9\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (1142 tokens).\n",
      "  💾 Saved pair: 00766588-c1d9-4039-ba22-a7e037c929b9_image.png, 00766588-c1d9-4039-ba22-a7e037c929b9_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 007c0c17-cd85-400a-bdf0-80f0e1eefe2d\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 11 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (1301 tokens).\n",
      "  💾 Saved pair: 007c0c17-cd85-400a-bdf0-80f0e1eefe2d_image.png, 007c0c17-cd85-400a-bdf0-80f0e1eefe2d_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00808820-c206-4cc8-98a5-6b7d2ff364af\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (237 tokens).\n",
      "  💾 Saved pair: 00808820-c206-4cc8-98a5-6b7d2ff364af_image.png, 00808820-c206-4cc8-98a5-6b7d2ff364af_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 008699e0-8d00-40f3-92b4-72347fa892c1\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 1 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (32 tokens).\n",
      "  💾 Saved pair: 008699e0-8d00-40f3-92b4-72347fa892c1_image.png, 008699e0-8d00-40f3-92b4-72347fa892c1_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 009ccdf2-5f3f-46e7-a562-10da2b2e3bb9\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (192 tokens).\n",
      "  💾 Saved pair: 009ccdf2-5f3f-46e7-a562-10da2b2e3bb9_image.png, 009ccdf2-5f3f-46e7-a562-10da2b2e3bb9_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00ad8345-45e0-45b3-867d-4a3c88c2517a\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (491 tokens).\n",
      "  💾 Saved pair: 00ad8345-45e0-45b3-867d-4a3c88c2517a_image.png, 00ad8345-45e0-45b3-867d-4a3c88c2517a_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00add26c-7a26-4a61-b192-b97aa493b3f3\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (271 tokens).\n",
      "  💾 Saved pair: 00add26c-7a26-4a61-b192-b97aa493b3f3_image.png, 00add26c-7a26-4a61-b192-b97aa493b3f3_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00b88e19-d106-4ab8-a322-31c494a0a6b9\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (770 tokens).\n",
      "  💾 Saved pair: 00b88e19-d106-4ab8-a322-31c494a0a6b9_image.png, 00b88e19-d106-4ab8-a322-31c494a0a6b9_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00c0c75e-1c12-46b3-9fc8-0561b1b1b510\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 2 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (68 tokens).\n",
      "  💾 Saved pair: 00c0c75e-1c12-46b3-9fc8-0561b1b1b510_image.png, 00c0c75e-1c12-46b3-9fc8-0561b1b1b510_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00de1e24-ab10-4aef-bb72-130ca18d017c\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (632 tokens).\n",
      "  💾 Saved pair: 00de1e24-ab10-4aef-bb72-130ca18d017c_image.png, 00de1e24-ab10-4aef-bb72-130ca18d017c_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00ecd5d3-d369-459f-8300-38fc159823dc\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (438 tokens).\n",
      "  💾 Saved pair: 00ecd5d3-d369-459f-8300-38fc159823dc_image.png, 00ecd5d3-d369-459f-8300-38fc159823dc_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00fc9d81-7397-4578-a865-920c4d89b44b\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hagai.LAPTOP-QAG9263N\\AppData\\Local\\Temp\\ipykernel_23276\\1891665349.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  img_shape = (np.ceil((max_coords - min_coords) * scale).astype(int) + 4)[::-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌❌❌ UNEXPECTED ERROR processing scene 00fc9d81-7397-4578-a865-920c4d89b44b. Skipping. ❌❌❌\n",
      "      Error details: Width and height must be >= 0\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 00fe8139-76e8-42b4-bb41-7f9f085ac351\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 10 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (227 tokens).\n",
      "  💾 Saved pair: 00fe8139-76e8-42b4-bb41-7f9f085ac351_image.png, 00fe8139-76e8-42b4-bb41-7f9f085ac351_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0106f9d2-5779-457b-9b8b-72942373d42e\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (205 tokens).\n",
      "  💾 Saved pair: 0106f9d2-5779-457b-9b8b-72942373d42e_image.png, 0106f9d2-5779-457b-9b8b-72942373d42e_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 011b264d-e2ef-426a-a4d5-d99de5bc68e2\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (580 tokens).\n",
      "  💾 Saved pair: 011b264d-e2ef-426a-a4d5-d99de5bc68e2_image.png, 011b264d-e2ef-426a-a4d5-d99de5bc68e2_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01492580-b04d-4865-932d-c6fc225ba3b8\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 10 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (142 tokens).\n",
      "  💾 Saved pair: 01492580-b04d-4865-932d-c6fc225ba3b8_image.png, 01492580-b04d-4865-932d-c6fc225ba3b8_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 015c0c73-e5fd-447d-9919-acf4786db46a\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (266 tokens).\n",
      "  💾 Saved pair: 015c0c73-e5fd-447d-9919-acf4786db46a_image.png, 015c0c73-e5fd-447d-9919-acf4786db46a_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 015ed8e0-35dc-41ab-9a9e-b3dbba4ec64a\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 10 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (435 tokens).\n",
      "  💾 Saved pair: 015ed8e0-35dc-41ab-9a9e-b3dbba4ec64a_image.png, 015ed8e0-35dc-41ab-9a9e-b3dbba4ec64a_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01655258-a4b1-45ff-b16d-bae0ffb189c7\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (814 tokens).\n",
      "  💾 Saved pair: 01655258-a4b1-45ff-b16d-bae0ffb189c7_image.png, 01655258-a4b1-45ff-b16d-bae0ffb189c7_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 016ce52b-8b1b-4d1d-b257-29fd76fbbb38\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "      ❗️ ERROR loading item 2021159376038362973376/model: image file is truncated\n",
      "      ❗️ ERROR loading item 2021159376038362973376/model: image file is truncated\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 2 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (398 tokens).\n",
      "  💾 Saved pair: 016ce52b-8b1b-4d1d-b257-29fd76fbbb38_image.png, 016ce52b-8b1b-4d1d-b257-29fd76fbbb38_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 016e8e9e-143b-4f12-9679-3ca930a1b6d6\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (476 tokens).\n",
      "  💾 Saved pair: 016e8e9e-143b-4f12-9679-3ca930a1b6d6_image.png, 016e8e9e-143b-4f12-9679-3ca930a1b6d6_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01805656-e66f-44b1-8bc1-5e722fff3fff\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (458 tokens).\n",
      "  💾 Saved pair: 01805656-e66f-44b1-8bc1-5e722fff3fff_image.png, 01805656-e66f-44b1-8bc1-5e722fff3fff_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0182566d-2912-4bc1-bd74-70a4e04eb67d\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 9 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (499 tokens).\n",
      "  💾 Saved pair: 0182566d-2912-4bc1-bd74-70a4e04eb67d_image.png, 0182566d-2912-4bc1-bd74-70a4e04eb67d_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01832fd4-ab39-461a-8ba7-7a65e7e5fef8\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (355 tokens).\n",
      "  💾 Saved pair: 01832fd4-ab39-461a-8ba7-7a65e7e5fef8_image.png, 01832fd4-ab39-461a-8ba7-7a65e7e5fef8_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01861393-3d82-4926-af4c-e2d29c6d0c0b\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 9 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (246 tokens).\n",
      "  💾 Saved pair: 01861393-3d82-4926-af4c-e2d29c6d0c0b_image.png, 01861393-3d82-4926-af4c-e2d29c6d0c0b_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0192a842-531c-419a-923e-28db4add8656\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (104 tokens).\n",
      "  💾 Saved pair: 0192a842-531c-419a-923e-28db4add8656_image.png, 0192a842-531c-419a-923e-28db4add8656_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01a90e65-5653-4b48-88fa-4aa780db0621\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 1 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (257 tokens).\n",
      "  💾 Saved pair: 01a90e65-5653-4b48-88fa-4aa780db0621_image.png, 01a90e65-5653-4b48-88fa-4aa780db0621_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01aa1db0-b73a-4270-807c-1b73268aac3b\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 11 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (2125 tokens).\n",
      "  💾 Saved pair: 01aa1db0-b73a-4270-807c-1b73268aac3b_image.png, 01aa1db0-b73a-4270-807c-1b73268aac3b_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01c978d0-4fe9-4ee4-9c1b-ac0788610445\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "      ❗️ ERROR loading item 61854/model: image file is truncated\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (938 tokens).\n",
      "  💾 Saved pair: 01c978d0-4fe9-4ee4-9c1b-ac0788610445_image.png, 01c978d0-4fe9-4ee4-9c1b-ac0788610445_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 01e8a481-e2fe-4811-a5d5-f47226c1c5c1\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (644 tokens).\n",
      "  💾 Saved pair: 01e8a481-e2fe-4811-a5d5-f47226c1c5c1_image.png, 01e8a481-e2fe-4811-a5d5-f47226c1c5c1_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0220df39-8356-4ba5-8f26-4f385afa2cae\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 14 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (345 tokens).\n",
      "  💾 Saved pair: 0220df39-8356-4ba5-8f26-4f385afa2cae_image.png, 0220df39-8356-4ba5-8f26-4f385afa2cae_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0220ea0d-1475-477e-b88e-ed571e3deed1\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (486 tokens).\n",
      "  💾 Saved pair: 0220ea0d-1475-477e-b88e-ed571e3deed1_image.png, 0220ea0d-1475-477e-b88e-ed571e3deed1_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 022bcb77-3234-43c5-b91a-0fc211f4a2c3\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 9 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (923 tokens).\n",
      "  💾 Saved pair: 022bcb77-3234-43c5-b91a-0fc211f4a2c3_image.png, 022bcb77-3234-43c5-b91a-0fc211f4a2c3_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0235e320-1523-44a5-be6f-20460e3e4a18\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 2 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (361 tokens).\n",
      "  💾 Saved pair: 0235e320-1523-44a5-be6f-20460e3e4a18_image.png, 0235e320-1523-44a5-be6f-20460e3e4a18_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 024b64f5-92d9-45e2-ac31-b61c1bbf9484\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (266 tokens).\n",
      "  💾 Saved pair: 024b64f5-92d9-45e2-ac31-b61c1bbf9484_image.png, 024b64f5-92d9-45e2-ac31-b61c1bbf9484_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0251ca05-b1cb-42ed-85b3-9cbc724ac967\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 4 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (389 tokens).\n",
      "  💾 Saved pair: 0251ca05-b1cb-42ed-85b3-9cbc724ac967_image.png, 0251ca05-b1cb-42ed-85b3-9cbc724ac967_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02623967-e0d7-4775-888e-6441b23a96ff\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 7 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (210 tokens).\n",
      "  💾 Saved pair: 02623967-e0d7-4775-888e-6441b23a96ff_image.png, 02623967-e0d7-4775-888e-6441b23a96ff_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 027dca3d-2675-43ab-a97d-0abc5910edef\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (110 tokens).\n",
      "  💾 Saved pair: 027dca3d-2675-43ab-a97d-0abc5910edef_image.png, 027dca3d-2675-43ab-a97d-0abc5910edef_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 0298054f-93f3-4365-8724-484202d53981\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 3 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (203 tokens).\n",
      "  💾 Saved pair: 0298054f-93f3-4365-8724-484202d53981_image.png, 0298054f-93f3-4365-8724-484202d53981_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02b90cf0-5313-425d-961e-3151b633c729\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 8 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (406 tokens).\n",
      "  💾 Saved pair: 02b90cf0-5313-425d-961e-3151b633c729_image.png, 02b90cf0-5313-425d-961e-3151b633c729_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02cdd750-72be-4bc5-a033-3c604919009f\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 2 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (113 tokens).\n",
      "  💾 Saved pair: 02cdd750-72be-4bc5-a033-3c604919009f_image.png, 02cdd750-72be-4bc5-a033-3c604919009f_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02e49abe-2551-4f90-9717-ac1b21dc5f6a\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 3 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (353 tokens).\n",
      "  💾 Saved pair: 02e49abe-2551-4f90-9717-ac1b21dc5f6a_image.png, 02e49abe-2551-4f90-9717-ac1b21dc5f6a_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02f7ad87-8aaf-49a0-bd98-c010e7b84c33\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 9 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (576 tokens).\n",
      "  💾 Saved pair: 02f7ad87-8aaf-49a0-bd98-c010e7b84c33_image.png, 02f7ad87-8aaf-49a0-bd98-c010e7b84c33_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 02fb72ea-8e75-4f7b-85bd-18798232b263\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 15 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (307 tokens).\n",
      "  💾 Saved pair: 02fb72ea-8e75-4f7b-85bd-18798232b263_image.png, 02fb72ea-8e75-4f7b-85bd-18798232b263_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 030345aa-f00e-4922-b50f-b56055702045\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 2 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (158 tokens).\n",
      "  💾 Saved pair: 030345aa-f00e-4922-b50f-b56055702045_image.png, 030345aa-f00e-4922-b50f-b56055702045_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 03279ac8-717b-4b94-96e1-3b6a7e94e782\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 5 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (158 tokens).\n",
      "  💾 Saved pair: 03279ac8-717b-4b94-96e1-3b6a7e94e782_image.png, 03279ac8-717b-4b94-96e1-3b6a7e94e782_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 032e5dbc-4026-4e03-84f1-e75553e339a3\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n",
      "  ✅ Image Generation Complete.\n",
      "  ▶️ Starting Token Generation...\n",
      "      - Found 6 rooms with furniture to tokenize.\n",
      "  ✅ Token Generation Complete (901 tokens).\n",
      "  💾 Saved pair: 032e5dbc-4026-4e03-84f1-e75553e339a3_image.png, 032e5dbc-4026-4e03-84f1-e75553e339a3_tokens.json\n",
      "\n",
      "------------------\n",
      "🎬 Processing Scene: 03386199-b47b-4417-85cc-cba4e8d28ee3\n",
      "------------------\n",
      "  ▶️ Starting Sliced Layout Generation...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 121\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=====================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Execute the main processing function\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m \u001b[43mrun_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Execute the main processing function\u001b[39;00m\n\u001b[0;32m    124\u001b[0m run_processing()\n",
      "Cell \u001b[1;32mIn[7], line 77\u001b[0m, in \u001b[0;36mrun_processing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(scene_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     75\u001b[0m     scene_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m---> 77\u001b[0m image, rotation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sliced_layout_render\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscene_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscene_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_info_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_info_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_z_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSLICE_Z_POSITION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_thickness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSLICE_THICKNESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADLESS_MODE\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Skipping scene \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Could not generate image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 102\u001b[0m, in \u001b[0;36mgenerate_sliced_layout_render\u001b[1;34m(scene_metadata, model_dir, model_info_map, color_map, slice_z_position, slice_thickness, headless)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pixel_coords)):\n\u001b[0;32m    101\u001b[0m     px, py \u001b[38;5;241m=\u001b[39m pixel_coords[i]\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m([px \u001b[38;5;241m-\u001b[39m point_radius, py \u001b[38;5;241m-\u001b[39m point_radius, px \u001b[38;5;241m+\u001b[39m point_radius, py \u001b[38;5;241m+\u001b[39m point_radius], fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(sorted_colors[i]))\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m headless: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ✅ Image Generation Complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m canvas, rotation_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_processing():\n",
    "    \"\"\"Main function to generate pairs from a pre-validated list of scenes.\"\"\"\n",
    "    try:\n",
    "        MODEL_DIR, MODEL_INFO_FILE = setup_paths(\n",
    "            model_dir_arg=MANUAL_MODEL_DIR,\n",
    "            model_info_arg=MANUAL_MODEL_INFO\n",
    "        )\n",
    "    except (AssertionError, FileNotFoundError) as e:\n",
    "        print(f\"❌ Error setting up paths: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Load Metadata, Scene List, and Setup Output ---\n",
    "    print(\"\\n--- 2. LOADING METADATA AND SETTING UP OUTPUT ---\")\n",
    "    with open(MODEL_INFO_FILE, 'r', encoding='utf-8') as f:\n",
    "        model_info_list = json.load(f)\n",
    "    model_info_map = {item['model_id']: item for item in model_info_list if 'model_id' in item}\n",
    "    print(f\"Loaded metadata for {len(model_info_map)} models.\")\n",
    "\n",
    "    if not SCENES_FILE_PATH.exists():\n",
    "        print(f\"❌ Error: Scenes file not found at '{SCENES_FILE_PATH}'.\")\n",
    "        print(\"    Please run the validation script first or provide the correct path in the configuration cell.\")\n",
    "        return\n",
    "    with open(SCENES_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        valid_scene_paths_str = json.load(f)\n",
    "    valid_scenes = [Path(p) for p in valid_scene_paths_str]\n",
    "    print(f\"Loaded a list of {len(valid_scenes)} scenes to process from '{SCENES_FILE_PATH.name}'.\")\n",
    "\n",
    "    if OUTPUT_PATH.exists():\n",
    "        print(f\"⚠️ Warning: Output directory '{OUTPUT_PATH}' already exists. Its contents will be removed.\")\n",
    "        shutil.rmtree(OUTPUT_PATH)\n",
    "    OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ Output will be saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "    # --- Pre-scan All Scenes to Build a Consistent Color Map ---\n",
    "    print(\"\\n--- 3. PRE-SCANNING SCENES FOR CONSISTENT COLOR SCHEME ---\")\n",
    "    all_possible_labels = set()\n",
    "    for scene_path in tqdm(valid_scenes, desc=\"Scanning for categories\"):\n",
    "        with open(scene_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data.get('furniture', []):\n",
    "            label = get_final_label(item, model_info_map)\n",
    "            if label:\n",
    "                all_possible_labels.add(label)\n",
    "\n",
    "    sorted_labels = sorted(list(all_possible_labels))\n",
    "    color_map = {}\n",
    "    for label in sorted_labels:\n",
    "        random.seed(hash(label)) # Use a deterministic seed\n",
    "        color_map[label] = (random.randint(50, 200), random.randint(50, 200), random.randint(50, 200))\n",
    "    \n",
    "    # --- MODIFICATION START: Updated wall and floor colors ---\n",
    "    color_map['wall'] = (0, 0, 0)          # Black\n",
    "    color_map['floor'] = (255, 255, 255)   # White\n",
    "    # --- MODIFICATION END ---\n",
    "\n",
    "    print(f\"Generated a consistent color map for {len(sorted_labels)} categories.\")\n",
    "\n",
    "    legend_path = OUTPUT_PATH / \"color_legend.json\"\n",
    "    with open(legend_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(color_map, f, indent=4)\n",
    "    print(f\"✅ Saved color legend to '{legend_path}'\")\n",
    "\n",
    "    # --- Process Scenes ---\n",
    "    print(\"\\n--- 4. PROCESSING SCENES AND GENERATING PAIRS ---\")\n",
    "    processed_count = 0\n",
    "    failed_scenes = []\n",
    "\n",
    "    for scene_path in tqdm(valid_scenes, desc=\"Generating pairs\"):\n",
    "        scene_id = scene_path.stem\n",
    "        try:\n",
    "            if not HEADLESS_MODE:\n",
    "                print(f\"\\n------------------\\n🎬 Processing Scene: {scene_id}\\n------------------\")\n",
    "\n",
    "            with open(scene_path, 'r', encoding='utf-8') as f:\n",
    "                scene_data = json.load(f)\n",
    "\n",
    "            image, rotation_matrix = generate_sliced_layout_render(\n",
    "                scene_metadata=scene_data, model_dir=MODEL_DIR,\n",
    "                model_info_map=model_info_map, color_map=color_map,\n",
    "                slice_z_position=SLICE_Z_POSITION, slice_thickness=SLICE_THICKNESS,\n",
    "                headless=HEADLESS_MODE\n",
    "            )\n",
    "            if image is None:\n",
    "                tqdm.write(f\"❌ Skipping scene {scene_id}: Could not generate image.\")\n",
    "                continue\n",
    "\n",
    "            tokens = generate_scene_graph_tokens(\n",
    "                scene_data, model_info_map, rotation_matrix, headless=HEADLESS_MODE\n",
    "            )\n",
    "            if not tokens:\n",
    "                tqdm.write(f\"❌ Skipping scene {scene_id}: Could not generate tokens.\")\n",
    "                continue\n",
    "\n",
    "            image_path = OUTPUT_PATH / f\"{scene_id}_image.png\"\n",
    "            image.save(image_path)\n",
    "            \n",
    "            tokens_path = OUTPUT_PATH / f\"{scene_id}_tokens.json\"\n",
    "            with open(tokens_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(tokens, f, indent=2)\n",
    "\n",
    "            if not HEADLESS_MODE:\n",
    "                print(f\"  💾 Saved pair: {image_path.name}, {tokens_path.name}\")\n",
    "            \n",
    "            processed_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"\\n❌❌❌ UNEXPECTED ERROR processing scene {scene_id}. Skipping. ❌❌❌\")\n",
    "            tqdm.write(f\"      Error details: {e}\")\n",
    "            failed_scenes.append(scene_id)\n",
    "\n",
    "    print(f\"\\n\\n=====================================================\")\n",
    "    print(f\"🎉 All tasks complete. {processed_count} image-token pairs saved in '{OUTPUT_PATH}'.\")\n",
    "    if failed_scenes:\n",
    "        print(f\"\\n⚠️ Encountered critical errors in {len(failed_scenes)} scene(s):\")\n",
    "        for f_id in failed_scenes:\n",
    "            print(f\"    - {f_id}\")\n",
    "    print(f\"=====================================================\")\n",
    "\n",
    "\n",
    "# Execute the main processing function\n",
    "run_processing()\n",
    "\n",
    "# Execute the main processing function\n",
    "run_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
